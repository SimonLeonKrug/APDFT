{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning the alchemical potential with the FCHL representation\n",
    "- optimization of kernel width\n",
    "- learning all elements together and elementwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['font.size'] = 20\n",
    "from matplotlib import cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "def load_obj(fname):\n",
    "    with open(fname, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def save_obj(obj, fname ):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def concatenate_different_sigma(small, large, newd):\n",
    "    \"\"\"\n",
    "    concatenate dict for same element but different sigma\n",
    "    \"\"\"\n",
    "    base = '/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/fchl/'\n",
    "    dict_small = load_obj(base+small)\n",
    "    dict_large = load_obj(base+large)\n",
    "    merged_dict = {**dict_small, **dict_large}\n",
    "\n",
    "    save_obj(merged_dict, base+newd)\n",
    "    \n",
    "def order_dict(unordered_dict):\n",
    "    ordered_dict = dict()\n",
    "    for ok in ordered_keys:\n",
    "        for uk in unordered_dict.keys():\n",
    "            sig_val = float(uk.split('_')[1])\n",
    "            if sig_val == ok:\n",
    "                ordered_dict[uk] = unordered_dict[uk]\n",
    "                \n",
    "    return(ordered_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_alchpots = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/fchl/best_all.txt')\n",
    "\n",
    "alchpots_H = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/fchl/best_H.txt')\n",
    "alchpots_C = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/fchl/best_C.txt')\n",
    "alchpots_N = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/fchl/best_N.txt')\n",
    "alchpots_O = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/fchl/best_O.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [all_alchpots, alchpots_H, alchpots_C, alchpots_N, alchpots_O]\n",
    "labels = [r'all $\\mu$', r'$\\mu_{\\rm{H}}$', r'$\\mu_{\\rm{C}}$', r'$\\mu_{\\rm{N}}$', r'$\\mu_{\\rm{O}}$']\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "# plt.rcParams.update({'errorbar.capsize': 0})\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "for d,l in zip(datasets, labels):\n",
    "    ax.errorbar(d[:,0], d[:,1], d[:,2], label=l)\n",
    "\n",
    "ax.set_xlabel('# Training points')\n",
    "ax.set_ylabel('MAE (Ha)')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcurves = load_obj('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/fchl/all_sigma_H.txt')\n",
    "NUM_COLORS = len(lcurves.keys())\n",
    "jet = cm = plt.get_cmap('jet') \n",
    "cNorm  = colors.Normalize(vmin=0, vmax=NUM_COLORS-1)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=jet)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "plt.rcParams['figure.figsize'] = [6.0, 4.0]\n",
    "ax.set_prop_cycle(color=[scalarMap.to_rgba(i) for i in range(NUM_COLORS)])\n",
    "for k in lcurves.keys():\n",
    "    ax.plot(lcurves[k][:,0], lcurves[k][:,1], '-o', label=r'$\\sigma = {}$'.format(np.round( float(k.split('_')[1]), 4 )) )\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves for alchemical potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qml\n",
    "import sys\n",
    "sys.path.insert(0, '/home/misa/git_repositories/APDFT/prototyping/atomic_energies/')\n",
    "import qml_interface as qmi\n",
    "import sklearn.model_selection as sk\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "# make atomic kernel for all atoms\n",
    "# for elementwise learning restrict kernel indices to the ones of the specifc element\n",
    "\n",
    "def crossvalidate_fchl(full_kernel, labels, tr_size, lam, num_cv):\n",
    "    errors = []\n",
    "    for cv in range(num_cv):\n",
    "        # select random indices for training/testing\n",
    "        tr_ind, test_ind = qmi.get_indices(len(labels), tr_size)\n",
    "        # split labels\n",
    "        labels_tr = labels[tr_ind]\n",
    "        labels_test = labels[test_ind]\n",
    "        # pick sub kernel for training/testing\n",
    "        tr_kernel, test_kernel = qmi.split_kernel(full_kernel, tr_ind, test_ind)\n",
    "        # calculate coefficients\n",
    "        reg_kernel = tr_kernel + np.identity(len(tr_kernel))*lam_val\n",
    "        coeffs = qml.math.cho_solve(reg_kernel, labels_tr)\n",
    "        # predict labels\n",
    "        labels_predicted = np.dot(test_kernel, coeffs)\n",
    "        errors.append((np.abs(labels_predicted - labels_test)).mean())\n",
    "    errors = np.array(errors)\n",
    "    return(errors.mean(), errors.std())\n",
    "\n",
    "def save_obj(obj, fname ):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "data, molecule_size = qmi.load_alchemy_data(qmi.wrapper_alch_data())\n",
    "alch_pots = qmi.generate_label_vector(data, molecule_size.sum(), value='alch_pot')\n",
    "\n",
    "# kernel path\n",
    "base_path = '/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/FCHL/'\n",
    "a=glob.glob(base_path+'full_kernel*')\n",
    "b=glob.glob(base_path+'full_kernel*_lam')\n",
    "kernel_paths = list(set(a)-set(b))\n",
    "# kernel_paths = ['full_kernel_alchoff_sig0.01', 'full_kernel_alchoff_sig0.001', 'full_kernel_alchoff_sig0.0001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation of learning curves\n",
    "sigmas = []\n",
    "for i in kernel_paths:\n",
    "    sigmas.append(i.split('_')[-1][3:])\n",
    "\n",
    "lam_val = 1e-5\n",
    "num_cv = 3\n",
    "\n",
    "lcurves = dict()\n",
    "\n",
    "# define number of training points for which MAE is calculated\n",
    "set_sizes = np.logspace(0, 11, 12, base=2).astype(int)\n",
    "\n",
    "for sigma, kernel_path in zip(sigmas, kernel_paths):\n",
    "    error_cv = []\n",
    "    error_std = []\n",
    "    # load kernel\n",
    "    kernel = np.loadtxt(kernel_path)\n",
    "    # calculate error for every training point size\n",
    "    for idx, tr_size in enumerate(set_sizes):\n",
    "        err, err_std = crossvalidate_fchl(kernel, alch_pots, tr_size, lam_val, num_cv)\n",
    "        error_cv.append(err)\n",
    "        error_std.append(err_std)\n",
    "    \n",
    "    lcurves[f'sig_{sigma}'] = np.array([set_sizes, error_cv, error_std]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_val = 0.1\n",
    "lam_val = 1e-5\n",
    "num_cv = 3\n",
    "# save best learning curve\n",
    "lowest_error = (None, None)\n",
    "for k in lcurves.keys():\n",
    "    if lowest_error[1]==None or lowest_error[1] > np.amin(lcurves[k][:,1]):\n",
    "        lowest_error = (k, np.amin(lcurves[k][:,1]))\n",
    "save_data = lcurves[lowest_error[0]]\n",
    "path = '/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/fchl/best_all_alchpots_small_sigmas.txt'\n",
    "sig_val = lowest_error[0].split('_')[1]\n",
    "header = f'sigma = {sig_val}, lambda = {lam_val}, number cv = {num_cv}'\n",
    "np.savetxt(path, save_data, delimiter='\\t', header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary of learning curves at all sigmas\n",
    "fname = '/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/fchl/all_sigma_all2'\n",
    "save_obj(lcurves, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves for alchemical potential of single elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qml\n",
    "import sys\n",
    "sys.path.insert(0, '/home/misa/git_repositories/APDFT/prototyping/atomic_energies/')\n",
    "import qml_interface as qmi\n",
    "import sklearn.model_selection as sk\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "def crossvalidate_fchl(full_kernel, labels, tr_size, lam, num_cv):\n",
    "    errors = []\n",
    "    for cv in range(num_cv):\n",
    "        # select random indices for training/testing\n",
    "        tr_ind, test_ind = qmi.get_indices(len(labels), tr_size)\n",
    "        # split labels\n",
    "        labels_tr = labels[tr_ind]\n",
    "        labels_test = labels[test_ind]\n",
    "        # pick sub kernel for training/testing\n",
    "        tr_kernel, test_kernel = qmi.split_kernel(full_kernel, tr_ind, test_ind)\n",
    "        # calculate coefficients\n",
    "        reg_kernel = tr_kernel + np.identity(len(tr_kernel))*lam_val\n",
    "        coeffs = qml.math.cho_solve(reg_kernel, labels_tr)\n",
    "        # predict labels\n",
    "        labels_predicted = np.dot(test_kernel, coeffs)\n",
    "        errors.append((np.abs(labels_predicted - labels_test)).mean())\n",
    "    errors = np.array(errors)\n",
    "    return(errors.mean(), errors.std())\n",
    "\n",
    "def save_obj(obj, fname ):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def get_tr_size(data_size):\n",
    "    \"\"\"\n",
    "    largest number of training points is roughly 90% of complete data (largest multiple of 2 that is <= 90%)\n",
    "    \"\"\"\n",
    "    largest_set = int(np.log2(data_size*0.9))\n",
    "    tr_size = np.logspace(0, largest_set, largest_set+1, base=2).astype(int)\n",
    "    return(tr_size)\n",
    "\n",
    "def get_element_symbol(Z):\n",
    "    if int(Z) == 1:\n",
    "        return('H')\n",
    "    elif int(Z) == 6:\n",
    "        return('C')\n",
    "    elif int(Z) == 7:\n",
    "        return('N')\n",
    "    elif int(Z) == 8:\n",
    "        return('O')\n",
    "    else:\n",
    "        raise ValueError('Symbol for given charge not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "data, molecule_size = qmi.load_alchemy_data(qmi.wrapper_alch_data())\n",
    "alch_pots = qmi.generate_label_vector(data, molecule_size.sum(), value='alch_pot')\n",
    "\n",
    "# split up alchemical potential by element\n",
    "charges = qmi.generate_label_vector(data, molecule_size.sum(), value='charge')\n",
    "idc_by_charge = qmi.partition_idx_by_charge(charges)\n",
    "\n",
    "el_alch_pots = dict()\n",
    "for k in idc_by_charge.keys():\n",
    "    el_alch_pots[k] = alch_pots[idc_by_charge[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel path\n",
    "base_path = '/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/FCHL/'\n",
    "a=glob.glob(base_path+'full_kernel*')\n",
    "b=glob.glob(base_path+'full_kernel*_lam')\n",
    "kernel_paths = list(set(a)-set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = [float(k.split('_')[-1][3:]) for k in kernel_paths]\n",
    "lam_val = 1e-5\n",
    "num_cv = 10\n",
    "\n",
    "for charge in idc_by_charge.keys():\n",
    "    lcurves = dict()\n",
    "\n",
    "    # define number of training points for which MAE is calculated\n",
    "    set_sizes = get_tr_size(len(el_alch_pots[charge]))\n",
    "    \n",
    "    # special for H\n",
    "#     set_sizes = np.concatenate((set_sizes, np.array([3300])))\n",
    "\n",
    "    for sigma, kernel_path in zip(sigmas, kernel_paths):\n",
    "\n",
    "        # calculate error for every training point size\n",
    "        error_cv = []\n",
    "        error_std = []\n",
    "        # load kernel\n",
    "        kernel = np.loadtxt(kernel_path)\n",
    "        # select subkernel for element\n",
    "        el_kernel = qmi.select_sub_matrix(kernel, idc_by_charge[charge], idc_by_charge[charge])\n",
    "        el_kernel = el_kernel.reshape((el_kernel.shape[0], el_kernel.shape[2]))\n",
    "        # calculate error for every training point size\n",
    "        for idx, tr_size in enumerate(set_sizes):\n",
    "            err, err_std = crossvalidate_fchl(el_kernel, el_alch_pots[charge], tr_size, lam_val, num_cv)\n",
    "            error_cv.append(err)\n",
    "            error_std.append(err_std)\n",
    "\n",
    "        lcurves[f'sig_{sigma}'] = np.array([set_sizes, error_cv, error_std]).T\n",
    "        \n",
    "    \n",
    "    # save best learning curve\n",
    "    lowest_error = (None, None)\n",
    "    for k in lcurves.keys():\n",
    "        if lowest_error[1]==None or lowest_error[1] > np.amin(lcurves[k][:,1]):\n",
    "            lowest_error = (k, np.amin(lcurves[k][:,1]))\n",
    "    save_data = lcurves[lowest_error[0]]\n",
    "\n",
    "    # filename\n",
    "    el_symbol = get_element_symbol(charge)\n",
    "    path = f'/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/fchl/best_{el_symbol}.txt'\n",
    "\n",
    "    sig_val = lowest_error[0].split('_')[1]\n",
    "    header = f'sigma = {sig_val}, lambda = {lam_val}, number cv = {num_cv}'\n",
    "    np.savetxt(path, save_data, delimiter='\\t', header=header)\n",
    "\n",
    "    # save dictionary of learning curves at all sigmas\n",
    "    fname = f'/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/fchl/all_sigma_{el_symbol}.txt'\n",
    "    save_obj(lcurves, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves for alchemical potential of single elements optimize $\\sigma$ and $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qml\n",
    "import sys\n",
    "sys.path.insert(0, '/home/misa/git_repositories/APDFT/prototyping/atomic_energies/')\n",
    "import qml_interface as qmi\n",
    "import sklearn.model_selection as sk\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "def crossvalidate_fchl(full_kernel, labels, tr_size, lam, num_cv):\n",
    "    errors = []\n",
    "    for cv in range(num_cv):\n",
    "        # select random indices for training/testing\n",
    "        tr_ind, test_ind = qmi.get_indices(len(labels), tr_size)\n",
    "        # split labels\n",
    "        labels_tr = labels[tr_ind]\n",
    "        labels_test = labels[test_ind]\n",
    "        # pick sub kernel for training/testing\n",
    "        tr_kernel, test_kernel = qmi.split_kernel(full_kernel, tr_ind, test_ind)\n",
    "        # calculate coefficients\n",
    "        reg_kernel = tr_kernel + np.identity(len(tr_kernel))*lam_val\n",
    "        coeffs = qml.math.cho_solve(reg_kernel, labels_tr)\n",
    "        # predict labels\n",
    "        labels_predicted = np.dot(test_kernel, coeffs)\n",
    "        errors.append((np.abs(labels_predicted - labels_test)).mean())\n",
    "    errors = np.array(errors)\n",
    "    return(errors.mean(), errors.std())\n",
    "\n",
    "def save_obj(obj, fname ):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def get_tr_size(data_size):\n",
    "    \"\"\"\n",
    "    largest number of training points is roughly 90% of complete data (largest multiple of 2 that is <= 90%)\n",
    "    \"\"\"\n",
    "    largest_set = int(np.log2(data_size*0.9))\n",
    "    tr_size = np.logspace(0, largest_set, largest_set+1, base=2).astype(int)\n",
    "    return(tr_size)\n",
    "\n",
    "def get_element_symbol(Z):\n",
    "    if int(Z) == 1:\n",
    "        return('H')\n",
    "    elif int(Z) == 6:\n",
    "        return('C')\n",
    "    elif int(Z) == 7:\n",
    "        return('N')\n",
    "    elif int(Z) == 8:\n",
    "        return('O')\n",
    "    else:\n",
    "        raise ValueError('Symbol for given charge not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "data, molecule_size = qmi.load_alchemy_data(qmi.wrapper_alch_data())\n",
    "alch_pots = qmi.generate_label_vector(data, molecule_size.sum(), value='alch_pot')\n",
    "\n",
    "# split up alchemical potential by element\n",
    "charges = qmi.generate_label_vector(data, molecule_size.sum(), value='charge')\n",
    "idc_by_charge = qmi.partition_idx_by_charge(charges)\n",
    "\n",
    "el_alch_pots = dict()\n",
    "for k in idc_by_charge.keys():\n",
    "    el_alch_pots[k] = alch_pots[idc_by_charge[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel path\n",
    "base_path = '/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/FCHL/'\n",
    "a=glob.glob(base_path+'full_kernel*')\n",
    "b=glob.glob(base_path+'full_kernel*_lam')\n",
    "kernel_paths = list(set(a)-set(b))\n",
    "\n",
    "kernel_paths = []\n",
    "for s in [0.1, 0.075, 0.05, 0.025, 0.01, 0.0075, 0.0050, 0.0025, 0.001]:\n",
    "    kernel_paths.append(f'{base_path}full_kernel_alchoff_sig{s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best sigmas\n",
    "sigmas = [0.1, 0.075, 0.05, 0.025, 0.01, 0.0075, 0.0050, 0.0025, 0.001]\n",
    "lam_vals = [1e-3, 1e-5, 1e-7, 1e-9, 1e-11]\n",
    "num_cv = 10\n",
    "\n",
    "for charge in el_alch_pots.keys():\n",
    "    lcurves = dict()\n",
    "\n",
    "    # define number of training points for which MAE is calculated\n",
    "    set_sizes = get_tr_size(len(el_alch_pots[charge]))\n",
    "    \n",
    "    # special for H\n",
    "#     set_sizes = np.concatenate((set_sizes, np.array([3300])))\n",
    "\n",
    "    for sigma, kernel_path in zip(sigmas, kernel_paths):\n",
    "        # load kernel\n",
    "        kernel = np.loadtxt(kernel_path)\n",
    "        # select subkernel for element\n",
    "        el_kernel = qmi.select_sub_matrix(kernel, idc_by_charge[charge], idc_by_charge[charge])\n",
    "        el_kernel = el_kernel.reshape((el_kernel.shape[0], el_kernel.shape[2]))\n",
    "        \n",
    "        for lam_val in lam_vals:\n",
    "            error_cv = []\n",
    "            error_std = []\n",
    "            # calculate error for every training point size\n",
    "            for idx, tr_size in enumerate(set_sizes):\n",
    "                err, err_std = crossvalidate_fchl(el_kernel, el_alch_pots[charge], tr_size, lam_val, num_cv)\n",
    "                error_cv.append(err)\n",
    "                error_std.append(err_std)\n",
    "\n",
    "            lcurves[f'sig_{sigma}_lam{lam_val}'] = np.array([set_sizes, error_cv, error_std]).T\n",
    "    \n",
    "#     # save best learning curve\n",
    "#     lowest_error = (None, None)\n",
    "#     for k in lcurves.keys():\n",
    "#         if lowest_error[1]==None or lowest_error[1] > np.amin(lcurves[k][:,1]):\n",
    "#             lowest_error = (k, np.amin(lcurves[k][:,1]))\n",
    "#     save_data = lcurves[lowest_error[0]]\n",
    "\n",
    "    # filename\n",
    "    el_symbol = get_element_symbol(charge)\n",
    "#     path = f'/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/best_alchpots_{el_symbol}.txt'\n",
    "\n",
    "#     sig_val = lowest_error[0].split('_')[1]\n",
    "#     header = f'sigma = {sig_val}, lambda = {lam_val}, number cv = {num_cv}'\n",
    "#     np.savetxt(path, save_data, delimiter='\\t', header=header)\n",
    "\n",
    "    # save dictionary of learning curves at all sigmas\n",
    "    fname = f'/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/fchl/all_sigma_all_lam_alchpots_{el_symbol}.txt'\n",
    "    save_obj(lcurves, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:atomic-energies]",
   "language": "python",
   "name": "conda-env-atomic-energies-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
