{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qml\n",
    "import sys\n",
    "sys.path.insert(0, '/home/misa/git_repositories/APDFT/prototyping/atomic_energies/')\n",
    "import qml_interface as qmi\n",
    "import sklearn.model_selection as sk\n",
    "import pickle\n",
    "\n",
    "from utils_qm import save_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "data, molecule_size = qmi.load_alchemy_data(qmi.wrapper_alch_data())\n",
    "\n",
    "global_reps = qmi.wrapper_global_representations(data, molecule_size) # all global representations\n",
    "\n",
    "global_labels = np.zeros(len(global_reps)) # all global labels\n",
    "for idx, mol in enumerate(data):\n",
    "    global_labels[idx] = data[idx][:,6].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = np.logspace(-1, 10, 11, base=2)\n",
    "lam_val = 1e-5\n",
    "num_cv = 3\n",
    "\n",
    "lcurves = dict()\n",
    "\n",
    "# define number of training points for which MAE is calculated\n",
    "set_sizes = np.logspace(0, 9, 10, base=2).astype(int)\n",
    "set_sizes = np.concatenate((set_sizes, np.array([900])))\n",
    "\n",
    "for sigma in sigmas:\n",
    "    error_cv = []\n",
    "    error_std = []\n",
    "    # calculate error for every training point size\n",
    "    for idx, tr_size in enumerate(set_sizes):\n",
    "        err, err_std = qmi.crossvalidate(global_reps, global_labels, tr_size, sigma, lam_val, num_cv)\n",
    "        error_cv.append(err)\n",
    "        error_std.append(err_std)\n",
    "    \n",
    "    lcurves[f'sig_{sigma}'] = np.array([set_sizes, error_cv, error_std]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best learning curve\n",
    "lowest_error = (None, None)\n",
    "for k in lcurves.keys():\n",
    "    if lowest_error[1]==None or lowest_error[1] > np.amin(lcurves[k][:,1]):\n",
    "        lowest_error = (k, np.amin(lcurves[k][:,1]))\n",
    "save_data = lcurves[lowest_error[0]]\n",
    "\n",
    "# filename\n",
    "path = '/home/misa/projects/Atomic-Energies/data/lcurves/lcurves_atomisation/best_atomisation_global_label.txt'\n",
    "\n",
    "sig_val = lowest_error[0].split('_')[1]\n",
    "header = f'sigma = {sig_val}, lambda = {lam_val}, number cv = {num_cv}'\n",
    "np.savetxt(path, save_data, delimiter='\\t', header=header)\n",
    "\n",
    "# save dictionary of learning curves at all sigmas\n",
    "fname = '/home/misa/projects/Atomic-Energies/data/lcurves/lcurves_atomisation/all_sigma_atomisation_global_label.txt'\n",
    "save_obj(lcurves, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:atomic-energies]",
   "language": "python",
   "name": "conda-env-atomic-energies-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
