{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['font.size'] = 20\n",
    "from matplotlib import cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "def load_obj(fname):\n",
    "    with open(fname, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def save_obj(obj, fname ):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def concatenate_different_sigma(small, large, newd):\n",
    "    \"\"\"\n",
    "    concatenate dict for same element but different sigma\n",
    "    \"\"\"\n",
    "    base = '/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/'\n",
    "    dict_small = load_obj(base+small)\n",
    "    dict_large = load_obj(base+large)\n",
    "    merged_dict = {**dict_small, **dict_large}\n",
    "\n",
    "    save_obj(merged_dict, base+newd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves with aslatm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_alchpots = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/best_sigma_all.txt')\n",
    "\n",
    "alchpots_H = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/best_sigma_H.txt')\n",
    "alchpots_C = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/best_sigma_C.txt')\n",
    "alchpots_N = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/best_sigma_N.txt')\n",
    "alchpots_O = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/best_sigma_O.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [all_alchpots, alchpots_H, alchpots_C, alchpots_N, alchpots_O]\n",
    "labels = [r'all $\\mu$', r'$\\mu_{\\rm{H}}$', r'$\\mu_{\\rm{C}}$', r'$\\mu_{\\rm{N}}$', r'$\\mu_{\\rm{O}}$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "# plt.rcParams.update({'errorbar.capsize': 0})\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "for d,l in zip(datasets, labels):\n",
    "    ax.errorbar(d[:,0], d[:,1], d[:,2], label=l)\n",
    "\n",
    "ax.set_xlabel('# Training points')\n",
    "ax.set_ylabel('MAE (Ha)')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare learning for different regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alchpots_C = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/best_sigma_C.txt')\n",
    "alchpots_C_largelam = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/best_sigma_large_lambda_C.txt')\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "ax.errorbar(alchpots_C[:,0], alchpots_C[:,1], alchpots_C[:,2], label=r'$\\mu_{\\rm{C}}, \\lambda = 10^{-5}$')\n",
    "ax.errorbar(alchpots_C_largelam[:,0], alchpots_C_largelam[:,1], alchpots_C_largelam[:,2], label=r'$\\mu_{\\rm{C}}, \\lambda = 10^{-3}$')\n",
    "ax.set_xlabel('# Training points')\n",
    "ax.set_ylabel('MAE (Ha)')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "# ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigma optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_alchpot_dict = load_obj('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/all_sigma_all_alchpots.txt')\n",
    "\n",
    "alchpot_dict = load_obj('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/all_sigma_H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict = alchpot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COLORS = len(plot_dict.keys())\n",
    "jet = cm = plt.get_cmap('jet') \n",
    "cNorm  = colors.Normalize(vmin=0, vmax=NUM_COLORS-1)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=jet)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "plt.rcParams['figure.figsize'] = [6.0, 4.0]\n",
    "ax.set_prop_cycle(color=[scalarMap.to_rgba(i) for i in range(NUM_COLORS)])\n",
    "for k in plot_dict.keys():\n",
    "    ax.plot(plot_dict[k][:,0], plot_dict[k][:,1], '-o', label=r'$\\sigma = {}$'.format(np.round( float(k.split('_')[1]), 2 )) )\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves for alchemical potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qml\n",
    "import sys\n",
    "sys.path.insert(0, '/home/misa/git_repositories/APDFT/prototyping/atomic_energies/')\n",
    "import qml_interface as qmi\n",
    "import sklearn.model_selection as sk\n",
    "import pickle\n",
    "\n",
    "def crossvalidate(reps, labels, tr_size, sigma, lam, num_cv):\n",
    "    errors = []\n",
    "    for cv in range(num_cv):\n",
    "        reps_tr, reps_test, labels_tr, labels_test = sk.train_test_split(reps,labels,train_size=tr_size)\n",
    "        coeffs = qmi.train_kernel(reps_tr, labels_tr, sigma, lam_val)\n",
    "        labels_predicted = qmi.predict_labels(reps_test, reps_tr, sigma, coeffs)\n",
    "        errors.append((np.abs(labels_predicted - labels_test)).mean())\n",
    "    errors = np.array(errors)\n",
    "    return(errors.mean(), errors.std())\n",
    "\n",
    "def get_aslatm(data, molecule_size):\n",
    "    # 1) get many body types\n",
    "    nuclear_charges = []\n",
    "    for d in data:\n",
    "        nuclear_charges.append(d[:,0])\n",
    "    mbtypes = qml.representations.get_slatm_mbtypes(nuclear_charges)\n",
    "    \n",
    "    # 2) generate reps for molecules\n",
    "    reps = []\n",
    "    for d in data:\n",
    "        reps.append(qml.representations.generate_slatm(d[:,1:4], d[:,0], mbtypes, local=True))\n",
    "        \n",
    "    # 3) convert into pure numpy array with dim N, M: where N number of atoms in data set and M length of representation\n",
    "    full_reps = np.empty((molecule_size.sum(),len(reps[0][0])))\n",
    "    j = 0\n",
    "    for r, l in zip(reps, molecule_size):\n",
    "        full_reps[j:j+l] = r\n",
    "        j += l\n",
    "    \n",
    "    return(full_reps)\n",
    "\n",
    "def save_obj(obj, fname ):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "data, molecule_size = qmi.load_alchemy_data(qmi.wrapper_alch_data())\n",
    "alch_pots = qmi.generate_label_vector(data, molecule_size.sum(), value='alch_pot')\n",
    "\n",
    "all_local_reps = get_aslatm(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn alch pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = np.logspace(-1, 10, 11, base=2)\n",
    "lam_val = 1e-5\n",
    "num_cv = 3\n",
    "\n",
    "lcurves = dict()\n",
    "\n",
    "# define number of training points for which MAE is calculated\n",
    "set_sizes = np.logspace(0, 11, 12, base=2).astype(int)\n",
    "\n",
    "for sigma in sigmas:\n",
    "    error_cv = []\n",
    "    error_std = []\n",
    "    # calculate error for every training point size\n",
    "    for idx, tr_size in enumerate(set_sizes):\n",
    "        err, err_std = crossvalidate(all_local_reps, alch_pots, tr_size, sigma, lam_val, num_cv)\n",
    "        error_cv.append(err)\n",
    "        error_std.append(err_std)\n",
    "    \n",
    "    lcurves[f'sig_{sigma}'] = np.array([set_sizes, error_cv, error_std]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best learning curve\n",
    "lowest_error = (None, None)\n",
    "for k in lcurves.keys():\n",
    "    if lowest_error[1]==None or lowest_error[1] > np.amin(lcurves[k][:,1]):\n",
    "        lowest_error = (k, np.amin(lcurves[k][:,1]))\n",
    "save_data = lcurves[lowest_error[0]]\n",
    "path = '/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/best_all_alchpots_small_sigmas.txt'\n",
    "sig_val = lowest_error[0].split('_')[1]\n",
    "header = f'sigma = {sig_val}, lambda = {lam_val}, number cv = {num_cv}'\n",
    "np.savetxt(path, save_data, delimiter='\\t', header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary of learning curves at all sigmas\n",
    "fname = '/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/all_sigma_all_alchpots_small_sigmas.txt'\n",
    "save_obj(lcurves, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves for alchemical potential of single elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qml\n",
    "import sys\n",
    "sys.path.insert(0, '/home/misa/git_repositories/APDFT/prototyping/atomic_energies/')\n",
    "import qml_interface as qmi\n",
    "import sklearn.model_selection as sk\n",
    "import pickle\n",
    "\n",
    "def get_aslatm(data, molecule_size):\n",
    "    # 1) get many body types\n",
    "    nuclear_charges = []\n",
    "    for d in data:\n",
    "        nuclear_charges.append(d[:,0])\n",
    "    mbtypes = qml.representations.get_slatm_mbtypes(nuclear_charges)\n",
    "    \n",
    "    # 2) generate reps for molecules\n",
    "    reps = []\n",
    "    for d in data:\n",
    "        reps.append(qml.representations.generate_slatm(d[:,1:4], d[:,0], mbtypes, local=True))\n",
    "        \n",
    "    # 3) convert into pure numpy array with dim N, M: where N number of atoms in data set and M length of representation\n",
    "    full_reps = np.empty((molecule_size.sum(),len(reps[0][0])))\n",
    "    j = 0\n",
    "    for r, l in zip(reps, molecule_size):\n",
    "        full_reps[j:j+l] = r\n",
    "        j += l\n",
    "    \n",
    "    return(full_reps)\n",
    "\n",
    "def crossvalidate(reps, labels, tr_size, sigma, lam, num_cv):\n",
    "    errors = []\n",
    "    for cv in range(num_cv):\n",
    "        reps_tr, reps_test, labels_tr, labels_test = sk.train_test_split(reps,labels,train_size=tr_size)\n",
    "        coeffs = qmi.train_kernel(reps_tr, labels_tr, sigma, lam_val)\n",
    "        labels_predicted = qmi.predict_labels(reps_test, reps_tr, sigma, coeffs)\n",
    "        errors.append((np.abs(labels_predicted - labels_test)).mean())\n",
    "    errors = np.array(errors)\n",
    "    return(errors.mean(), errors.std())\n",
    "\n",
    "def save_obj(obj, fname ):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def get_tr_size(data_size):\n",
    "    \"\"\"\n",
    "    largest number of training points is roughly 90% of complete data (largest multiple of 2 that is <= 90%)\n",
    "    \"\"\"\n",
    "    largest_set = int(np.log2(data_size*0.9))\n",
    "    tr_size = np.logspace(0, largest_set, largest_set+1, base=2).astype(int)\n",
    "    return(tr_size)\n",
    "\n",
    "def get_element_symbol(Z):\n",
    "    if int(Z) == 1:\n",
    "        return('H')\n",
    "    elif int(Z) == 6:\n",
    "        return('C')\n",
    "    elif int(Z) == 7:\n",
    "        return('N')\n",
    "    elif int(Z) == 8:\n",
    "        return('O')\n",
    "    else:\n",
    "        raise ValueError('Symbol for given charge not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "data, molecule_size = qmi.load_alchemy_data(qmi.wrapper_alch_data())\n",
    "alch_pots = qmi.generate_label_vector(data, molecule_size.sum(), value='alch_pot')\n",
    "\n",
    "all_local_reps = get_aslatm(data, molecule_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up alchemical potential by element\n",
    "charges = qmi.generate_label_vector(data, molecule_size.sum(), value='charge')\n",
    "idc_by_charge = qmi.partition_idx_by_charge(charges)\n",
    "\n",
    "el_reps =dict()\n",
    "el_alch_pots = dict()\n",
    "for k in idc_by_charge.keys():\n",
    "    el_reps[k] = all_local_reps[idc_by_charge[k]]\n",
    "    el_alch_pots[k] = alch_pots[idc_by_charge[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = np.logspace(-6, 10, 11, base=2)#np.logspace(-1, 10, 11, base=2) # np.logspace(-6, -2, 5, base=2)\n",
    "lam_val = 1e-3\n",
    "num_cv = 3\n",
    "\n",
    "for charge in el_reps.keys():\n",
    "    lcurves = dict()\n",
    "\n",
    "    # define number of training points for which MAE is calculated\n",
    "    set_sizes = get_tr_size(len(el_alch_pots[charge]))\n",
    "    \n",
    "    # special for H\n",
    "#     set_sizes = np.concatenate((set_sizes, np.array([3300])))\n",
    "\n",
    "    for sigma in sigmas:\n",
    "        error_cv = []\n",
    "        error_std = []\n",
    "        # calculate error for every training point size\n",
    "        for idx, tr_size in enumerate(set_sizes):\n",
    "            err, err_std = crossvalidate(el_reps[charge], el_alch_pots[charge], tr_size, sigma, lam_val, num_cv)\n",
    "            error_cv.append(err)\n",
    "            error_std.append(err_std)\n",
    "\n",
    "        lcurves[f'sig_{sigma}'] = np.array([set_sizes, error_cv, error_std]).T\n",
    "        \n",
    "    \n",
    "    # save best learning curve\n",
    "    lowest_error = (None, None)\n",
    "    for k in lcurves.keys():\n",
    "        if lowest_error[1]==None or lowest_error[1] > np.amin(lcurves[k][:,1]):\n",
    "            lowest_error = (k, np.amin(lcurves[k][:,1]))\n",
    "    save_data = lcurves[lowest_error[0]]\n",
    "\n",
    "    # filename\n",
    "    el_symbol = get_element_symbol(charge)\n",
    "    path = f'/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/best_alchpots_large_lambda_sigma_{el_symbol}.txt'\n",
    "\n",
    "    sig_val = lowest_error[0].split('_')[1]\n",
    "    header = f'sigma = {sig_val}, lambda = {lam_val}, number cv = {num_cv}'\n",
    "    np.savetxt(path, save_data, delimiter='\\t', header=header)\n",
    "\n",
    "    # save dictionary of learning curves at all sigmas\n",
    "    fname = f'/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/large_lambda_all_sigma_alchpots_{el_symbol}.txt'\n",
    "    save_obj(lcurves, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if conversion from list of np-arrays to np-array was carried out correctly\n",
    "a = 0\n",
    "for j in range(len(reps)):\n",
    "    for i in range(molecule_size[j]):\n",
    "        a += (reps[j][i] - full_reps[molecule_size[0:j].sum()+i]).sum()\n",
    "print(a)\n",
    "print(len(reps[0])+len(reps[1])+len(reps[2]))\n",
    "print((reps[3][2] - full_reps[56]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate learning curves for NMR shifts from aSLATM and compare to results in Bing's Amon paper\n",
    "https://github.com/binghuang2018/aqml-data/tree/master/qm9-3mols/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import qml\n",
    "import sys\n",
    "sys.path.insert(0, '/home/misa/git_repositories/APDFT/prototyping/atomic_energies/')\n",
    "import qml_interface as qmi\n",
    "import sklearn.model_selection as sk\n",
    "import pickle\n",
    "\n",
    "def get_aslatm(data, molecule_size):\n",
    "    # 1) get many body types\n",
    "    nuclear_charges = []\n",
    "    for d in data:\n",
    "        nuclear_charges.append(d[:,0])\n",
    "    mbtypes = qml.representations.get_slatm_mbtypes(nuclear_charges)\n",
    "    \n",
    "    # 2) generate reps for atoms\n",
    "    reps = []\n",
    "    for d in data:\n",
    "        reps.append(qml.representations.generate_slatm(d[:,1:4], d[:,0], mbtypes, local=True))\n",
    "        \n",
    "    # 3) convert into pure numpy array with dim N, M: where N number of atoms in data set and M length of representation\n",
    "    full_reps = np.empty((molecule_size.sum(),len(reps[0][0])))\n",
    "    j = 0\n",
    "    for r, l in zip(reps, molecule_size):\n",
    "        full_reps[j:j+l] = r\n",
    "        j += l\n",
    "    \n",
    "    return(full_reps)\n",
    "\n",
    "def crossvalidate(reps, labels, tr_size, sigma, lam, num_cv):\n",
    "    errors = []\n",
    "    for cv in range(num_cv):\n",
    "        reps_tr, reps_test, labels_tr, labels_test = sk.train_test_split(reps,labels,train_size=tr_size)\n",
    "        coeffs = qmi.train_kernel(reps_tr, labels_tr, sigma, lam_val)\n",
    "        labels_predicted = qmi.predict_labels(reps_test, reps_tr, sigma, coeffs)\n",
    "        errors.append((np.abs(labels_predicted - labels_test)).mean())\n",
    "    errors = np.array(errors)\n",
    "    return(errors.mean(), errors.std())\n",
    "\n",
    "def save_obj(obj, fname ):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def get_tr_size(data_size):\n",
    "    \"\"\"\n",
    "    largest number of training points is roughly 90% of complete data (largest multiple of 2 that is <= 90%)\n",
    "    \"\"\"\n",
    "    largest_set = int(np.log2(data_size*0.9))\n",
    "    tr_size = np.logspace(0, largest_set, largest_set+1, base=2).astype(int)\n",
    "    return(tr_size)\n",
    "\n",
    "def get_element_symbol(Z):\n",
    "    if int(Z) == 1:\n",
    "        return('H')\n",
    "    elif int(Z) == 6:\n",
    "        return('C')\n",
    "    elif int(Z) == 7:\n",
    "        return('N')\n",
    "    elif int(Z) == 8:\n",
    "        return('O')\n",
    "    else:\n",
    "        raise ValueError('Symbol for given charge not available')\n",
    "        \n",
    "def parse_file(lines):\n",
    "    # remove \\n\n",
    "    for idx, l in enumerate(lines):\n",
    "        lines[idx] = l.strip('\\n')\n",
    "    \n",
    "    xyz_data = np.empty((len(lines), 6))\n",
    "    \n",
    "    for idx, l in enumerate(lines):\n",
    "        tmp = l.split()\n",
    "        if tmp[0] == 'H':\n",
    "            tmp[0] = 1.0\n",
    "        elif tmp[0] == 'C':\n",
    "            tmp[0] = 6.0\n",
    "        elif tmp[0] == 'N':\n",
    "            tmp[0] = 7.0\n",
    "        elif tmp[0] == 'O':\n",
    "            tmp[0] = 8.0\n",
    "        for i, j in enumerate(tmp):\n",
    "            tmp[i] = float(j)\n",
    "        xyz_data[idx] = tmp\n",
    "            \n",
    "    \n",
    "    return(xyz_data)\n",
    "\n",
    "def split_tr_test(data_in, idx=19):\n",
    "    return(data_in[:-19], data_in[-19:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download xyz-files\n",
    "# change element symbol to charge number\n",
    "# make data list of similar shape as alchemy data\n",
    "# generate learning curves, compare to Bing's results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse data from Bing, make data list of similar shape as alchemy data\n",
    "aqml_path = '/home/misa/git_repositories/aqml-data/qm9-3mols/03/g7/'\n",
    "aqml_files = glob.glob(aqml_path+'*')\n",
    "\n",
    "path_target = '/home/misa/git_repositories/aqml-data/qm9-3mols/03/target/03.xyz'\n",
    "aqml_files.append(path_target)\n",
    "\n",
    "files = []\n",
    "for path in aqml_files:\n",
    "    with open(path, 'r') as fs:\n",
    "        files.append(fs.readlines()[2:])\n",
    "\n",
    "data = []\n",
    "for f in files:\n",
    "    data.append(parse_file(f))\n",
    "    \n",
    "molecule_size = []\n",
    "for d in data:\n",
    "    molecule_size.append(d.shape[0])\n",
    "molecule_size = np.array(molecule_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_local_reps = get_aslatm(data, molecule_size)\n",
    "nmr_shifts = []\n",
    "for d in data:\n",
    "    nmr_shifts.extend(d[:, 5])\n",
    "nmr_shifts = np.array(nmr_shifts)\n",
    "\n",
    "charges = qmi.generate_label_vector(data, molecule_size.sum(), value='charge')\n",
    "idc_by_charge = qmi.partition_idx_by_charge(charges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training and test\n",
    "reps_tr, reps_test = split_tr_test(all_local_reps)\n",
    "nmr_shifts_tr, nmr_shifts_test = split_tr_test(nmr_shifts)\n",
    "charges_tr, charges_test = split_tr_test(charges)\n",
    "idc_by_charge_tr = qmi.partition_idx_by_charge(charges_tr)\n",
    "idc_by_charge_test = qmi.partition_idx_by_charge(charges_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split reps, labels bz element\n",
    "el_reps_tr =dict()\n",
    "el_nmr_tr = dict()\n",
    "for k in idc_by_charge_tr.keys():\n",
    "    el_reps_tr[k] = reps_tr[idc_by_charge_tr[k]]\n",
    "    el_nmr_tr[k] = nmr_shifts_tr[idc_by_charge_tr[k]]\n",
    "\n",
    "el_reps_test =dict()\n",
    "el_nmr_test = dict()\n",
    "for k in idc_by_charge_test.keys():\n",
    "    el_reps_test[k] = reps_test[idc_by_charge_test[k]]\n",
    "    el_nmr_test[k] = nmr_shifts_test[idc_by_charge_test[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best sigma\n",
    "distances = []\n",
    "for r in range(len(all_local_reps)):\n",
    "    for j in range(r+1, len(all_local_reps)):\n",
    "        distances.append(np.linalg.norm(all_local_reps[r]-all_local_reps[j]))\n",
    "distances = np.array(distances)\n",
    "\n",
    "sigma_opt = np.amax(distances)/np.sqrt(2*np.log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.541198699239287"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_val = 1e-8\n",
    "\n",
    "lcurves = dict()\n",
    "\n",
    "# define number of training points for which MAE is calculated\n",
    "set_sizes = np.logspace(0, 8, 9, base=2).astype(int)\n",
    "\n",
    "# calculate error for every training point size\n",
    "for k in el_reps_tr.keys():\n",
    "    coeffs = qmi.train_kernel(el_reps_tr[k], el_nmr_tr[k], sigma_opt, lam_val)\n",
    "    labels_predicted = qmi.predict_labels(el_reps_test[k], el_reps_tr[k], sigma_opt, coeffs)\n",
    "    err = (np.abs(labels_predicted - el_nmr_test[k])).mean()\n",
    "    err_std = (np.abs(labels_predicted - el_nmr_test[k])).std()\n",
    "    lcurves[k] = [err, err_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(el_reps_tr[6.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: [0.0016533259699176902, 0.0013544154735222699],\n",
       " 6.0: [0.012321129405275756, 0.013389753563229337],\n",
       " 8.0: [0.005038414580002176, 0.001827056789045045]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:atomic-energies]",
   "language": "python",
   "name": "conda-env-atomic-energies-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
