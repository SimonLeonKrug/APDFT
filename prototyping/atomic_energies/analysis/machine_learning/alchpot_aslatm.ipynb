{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['font.size'] = 20\n",
    "from matplotlib import cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "def load_obj(fname):\n",
    "    with open(fname, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_alchpots = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/best_all_alchpots.txt')\n",
    "\n",
    "alchpots_H = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/best_alchpots_H.txt')\n",
    "alchpots_C = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/best_alchpots_C.txt')\n",
    "alchpots_N = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/best_alchpots_N.txt')\n",
    "alchpots_O = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/best_alchpots_O.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [all_alchpots, alchpots_H, alchpots_C, alchpots_N, alchpots_O]\n",
    "labels = [r'all $\\mu$', r'$\\mu_{\\rm{H}}$', r'$\\mu_{\\rm{C}}$', r'$\\mu_{\\rm{N}}$', r'$\\mu_{\\rm{O}}$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "# plt.rcParams.update({'errorbar.capsize': 0})\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "for d,l in zip(datasets, labels):\n",
    "    ax.errorbar(d[:,0], d[:,1], d[:,2], label=l)\n",
    "\n",
    "ax.set_xlabel('# Training points')\n",
    "ax.set_ylabel('MAE (Ha)')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sigma optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_alchpot_dict = load_obj('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/all_sigma_all_alchpots.txt')\n",
    "\n",
    "alchpot_H_dict = load_obj('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/all_sigma_alchpots_H.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict = alchpot_H_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COLORS = len(lcurves.keys())\n",
    "jet = cm = plt.get_cmap('jet') \n",
    "cNorm  = colors.Normalize(vmin=0, vmax=NUM_COLORS-1)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=jet)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "plt.rcParams['figure.figsize'] = [6.0, 4.0]\n",
    "ax.set_prop_cycle(color=[scalarMap.to_rgba(i) for i in range(NUM_COLORS)])\n",
    "for k in plot_dict.keys():\n",
    "    ax.plot(plot_dict[k][:,0], plot_dict[k][:,1], '-o', label=r'$\\sigma = {}$'.format(np.round( float(k.split('_')[1]), 2 )) )\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves for alchemical potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qml\n",
    "import sys\n",
    "sys.path.insert(0, '/home/misa/git_repositories/APDFT/prototyping/atomic_energies/')\n",
    "import qml_interface as qmi\n",
    "import sklearn.model_selection as sk\n",
    "import pickle\n",
    "\n",
    "def crossvalidate(reps, labels, tr_size, sigma, lam, num_cv):\n",
    "    errors = []\n",
    "    for cv in range(num_cv):\n",
    "        reps_tr, reps_test, labels_tr, labels_test = sk.train_test_split(reps,labels,train_size=tr_size)\n",
    "        coeffs = qmi.train_kernel(reps_tr, labels_tr, sigma, lam_val)\n",
    "        labels_predicted = qmi.predict_labels(reps_test, reps_tr, sigma, coeffs)\n",
    "        errors.append((np.abs(labels_predicted - labels_test)).mean())\n",
    "    errors = np.array(errors)\n",
    "    return(errors.mean(), errors.std())\n",
    "\n",
    "def get_aslatm(data, molecule_size):\n",
    "    # 1) get many body types\n",
    "    nuclear_charges = []\n",
    "    for d in data:\n",
    "        nuclear_charges.append(d[:,0])\n",
    "    mbtypes = qml.representations.get_slatm_mbtypes(nuclear_charges)\n",
    "    \n",
    "    # 2) generate reps for molecules\n",
    "    reps = []\n",
    "    for d in data:\n",
    "        reps.append(qml.representations.generate_slatm(d[:,1:4], d[:,0], mbtypes, local=True))\n",
    "        \n",
    "    # 3) convert into pure numpy array with dim N, M: where N number of atoms in data set and M length of representation\n",
    "    full_reps = np.empty((molecule_size.sum(),len(reps[0][0])))\n",
    "    j = 0\n",
    "    for r, l in zip(reps, molecule_size):\n",
    "        full_reps[j:j+l] = r\n",
    "        j += l\n",
    "    \n",
    "    return(full_reps)\n",
    "\n",
    "def save_obj(obj, fname ):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "data, molecule_size = qmi.load_alchemy_data(qmi.wrapper_alch_data())\n",
    "alch_pots = qmi.generate_label_vector(data, molecule_size.sum(), value='alch_pot')\n",
    "\n",
    "all_local_reps = get_aslatm(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn alch pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = np.logspace(-1, 10, 11, base=2)\n",
    "lam_val = 1e-5\n",
    "num_cv = 3\n",
    "\n",
    "lcurves = dict()\n",
    "\n",
    "# define number of training points for which MAE is calculated\n",
    "set_sizes = np.logspace(0, 11, 12, base=2).astype(int)\n",
    "\n",
    "for sigma in sigmas:\n",
    "    error_cv = []\n",
    "    error_std = []\n",
    "    # calculate error for every training point size\n",
    "    for idx, tr_size in enumerate(set_sizes):\n",
    "        err, err_std = crossvalidate(all_local_reps, alch_pots, tr_size, sigma, lam_val, num_cv)\n",
    "        error_cv.append(err)\n",
    "        error_std.append(err_std)\n",
    "    \n",
    "    lcurves[f'sig_{sigma}'] = np.array([set_sizes, error_cv, error_std]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best learning curve\n",
    "lowest_error = (None, None)\n",
    "for k in lcurves.keys():\n",
    "    if lowest_error[1]==None or lowest_error[1] > np.amin(lcurves[k][:,1]):\n",
    "        lowest_error = (k, np.amin(lcurves[k][:,1]))\n",
    "save_data = lcurves[lowest_error[0]]\n",
    "path = '/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/best_all_alchpots_small_sigmas.txt'\n",
    "sig_val = lowest_error[0].split('_')[1]\n",
    "header = f'sigma = {sig_val}, lambda = {lam_val}, number cv = {num_cv}'\n",
    "np.savetxt(path, save_data, delimiter='\\t', header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary of learning curves at all sigmas\n",
    "fname = '/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/all_sigma_all_alchpots_small_sigmas.txt'\n",
    "save_obj(lcurves, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves for alchemical potential of single elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qml\n",
    "import sys\n",
    "sys.path.insert(0, '/home/misa/git_repositories/APDFT/prototyping/atomic_energies/')\n",
    "import qml_interface as qmi\n",
    "import sklearn.model_selection as sk\n",
    "import pickle\n",
    "\n",
    "def get_aslatm(data, molecule_size):\n",
    "    # 1) get many body types\n",
    "    nuclear_charges = []\n",
    "    for d in data:\n",
    "        nuclear_charges.append(d[:,0])\n",
    "    mbtypes = qml.representations.get_slatm_mbtypes(nuclear_charges)\n",
    "    \n",
    "    # 2) generate reps for molecules\n",
    "    reps = []\n",
    "    for d in data:\n",
    "        reps.append(qml.representations.generate_slatm(d[:,1:4], d[:,0], mbtypes, local=True))\n",
    "        \n",
    "    # 3) convert into pure numpy array with dim N, M: where N number of atoms in data set and M length of representation\n",
    "    full_reps = np.empty((molecule_size.sum(),len(reps[0][0])))\n",
    "    j = 0\n",
    "    for r, l in zip(reps, molecule_size):\n",
    "        full_reps[j:j+l] = r\n",
    "        j += l\n",
    "    \n",
    "    return(full_reps)\n",
    "\n",
    "def crossvalidate(reps, labels, tr_size, sigma, lam, num_cv):\n",
    "    errors = []\n",
    "    for cv in range(num_cv):\n",
    "        reps_tr, reps_test, labels_tr, labels_test = sk.train_test_split(reps,labels,train_size=tr_size)\n",
    "        coeffs = qmi.train_kernel(reps_tr, labels_tr, sigma, lam_val)\n",
    "        labels_predicted = qmi.predict_labels(reps_test, reps_tr, sigma, coeffs)\n",
    "        errors.append((np.abs(labels_predicted - labels_test)).mean())\n",
    "    errors = np.array(errors)\n",
    "    return(errors.mean(), errors.std())\n",
    "\n",
    "def save_obj(obj, fname ):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def get_tr_size(data_size):\n",
    "    \"\"\"\n",
    "    largest number of training points is roughly 90% of complete data (largest multiple of 2 that is <= 90%)\n",
    "    \"\"\"\n",
    "    largest_set = int(np.log2(data_size*0.9))\n",
    "    tr_size = np.logspace(0, largest_set, largest_set+1, base=2).astype(int)\n",
    "    return(tr_size)\n",
    "\n",
    "def get_element_symbol(Z):\n",
    "    if int(Z) == 1:\n",
    "        return('H')\n",
    "    elif int(Z) == 6:\n",
    "        return('C')\n",
    "    elif int(Z) == 7:\n",
    "        return('N')\n",
    "    elif int(Z) == 8:\n",
    "        return('O')\n",
    "    else:\n",
    "        raise ValueError('Symbol for given charge not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "data, molecule_size = qmi.load_alchemy_data(qmi.wrapper_alch_data())\n",
    "alch_pots = qmi.generate_label_vector(data, molecule_size.sum(), value='alch_pot')\n",
    "\n",
    "all_local_reps = get_aslatm(data, molecule_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up alchemical potential by element\n",
    "charges = qmi.generate_label_vector(data, molecule_size.sum(), value='charge')\n",
    "idc_by_charge = qmi.partition_idx_by_charge(charges)\n",
    "\n",
    "el_reps =dict()\n",
    "el_alch_pots = dict()\n",
    "for k in idc_by_charge.keys():\n",
    "    el_reps[k] = all_local_reps[idc_by_charge[k]]\n",
    "    el_alch_pots[k] = alch_pots[idc_by_charge[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a2064724dcff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# calculate error for every training point size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel_reps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcharge\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mel_alch_pots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcharge\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0merror_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0merror_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b4d94d3ea73d>\u001b[0m in \u001b[0;36mcrossvalidate\u001b[0;34m(reps, labels, tr_size, sigma, lam, num_cv)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mreps_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreps_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtr_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mcoeffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqmi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreps_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mlabels_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqmi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreps_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreps_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_predicted\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_repositories/APDFT/prototyping/atomic_energies/qml_interface.py\u001b[0m in \u001b[0;36mtrain_kernel\u001b[0;34m(rep_tr, labels_tr, sigma, lam_val)\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0mlam_val\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \"\"\"\n\u001b[0;32m--> 672\u001b[0;31m     \u001b[0mtr_kernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrep_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m     \u001b[0mreg_kernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr_kernel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlam_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0mcoeffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcho_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/qml/kernels/kernels.py\u001b[0m in \u001b[0;36mgaussian_kernel\u001b[0;34m(A, B, sigma)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m# Note: Transposed for Fortran\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mfgaussian_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sigmas = np.logspace(-6, 10, 11, base=2)#np.logspace(-1, 10, 11, base=2) # np.logspace(-6, -2, 5, base=2)\n",
    "lam_val = 1e-3\n",
    "num_cv = 3\n",
    "\n",
    "for charge in el_reps.keys():\n",
    "    lcurves = dict()\n",
    "\n",
    "    # define number of training points for which MAE is calculated\n",
    "    set_sizes = get_tr_size(len(el_alch_pots[charge]))\n",
    "    \n",
    "    # special for H\n",
    "#     set_sizes = np.concatenate((set_sizes, np.array([3300])))\n",
    "\n",
    "    for sigma in sigmas:\n",
    "        error_cv = []\n",
    "        error_std = []\n",
    "        # calculate error for every training point size\n",
    "        for idx, tr_size in enumerate(set_sizes):\n",
    "            err, err_std = crossvalidate(el_reps[charge], el_alch_pots[charge], tr_size, sigma, lam_val, num_cv)\n",
    "            error_cv.append(err)\n",
    "            error_std.append(err_std)\n",
    "\n",
    "        lcurves[f'sig_{sigma}'] = np.array([set_sizes, error_cv, error_std]).T\n",
    "        \n",
    "    \n",
    "    # save best learning curve\n",
    "    lowest_error = (None, None)\n",
    "    for k in lcurves.keys():\n",
    "        if lowest_error[1]==None or lowest_error[1] > np.amin(lcurves[k][:,1]):\n",
    "            lowest_error = (k, np.amin(lcurves[k][:,1]))\n",
    "    save_data = lcurves[lowest_error[0]]\n",
    "\n",
    "    # filename\n",
    "    el_symbol = get_element_symbol(charge)\n",
    "    path = f'/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/best_alchpots_large_lambda_sigma_{el_symbol}.txt'\n",
    "\n",
    "    sig_val = lowest_error[0].split('_')[1]\n",
    "    header = f'sigma = {sig_val}, lambda = {lam_val}, number cv = {num_cv}'\n",
    "    np.savetxt(path, save_data, delimiter='\\t', header=header)\n",
    "\n",
    "    # save dictionary of learning curves at all sigmas\n",
    "    fname = f'/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/large_lambda_all_sigma_alchpots_{el_symbol}.txt'\n",
    "    save_obj(lcurves, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qml\n",
    "import sys\n",
    "sys.path.insert(0, '/home/misa/git_repositories/APDFT/prototyping/atomic_energies/')\n",
    "import qml_interface as qmi\n",
    "import sklearn.model_selection as sk\n",
    "import pickle\n",
    "\n",
    "def get_aslatm(data, molecule_size):\n",
    "    # 1) get many body types\n",
    "    nuclear_charges = []\n",
    "    for d in data:\n",
    "        nuclear_charges.append(d[:,0])\n",
    "    mbtypes = qml.representations.get_slatm_mbtypes(nuclear_charges)\n",
    "    \n",
    "    # 2) generate reps for molecules\n",
    "    reps = []\n",
    "    for d in data:\n",
    "        reps.append(qml.representations.generate_slatm(d[:,1:4], d[:,0], mbtypes, local=True))\n",
    "        \n",
    "    # 3) convert into pure numpy array with dim N, M: where N number of atoms in data set and M length of representation\n",
    "    full_reps = np.empty((molecule_size.sum(),len(reps[0][0])))\n",
    "    j = 0\n",
    "    for r, l in zip(reps, molecule_size):\n",
    "        full_reps[j:j+l] = r\n",
    "        j += l\n",
    "    \n",
    "    return(full_reps)\n",
    "\n",
    "def crossvalidate(reps, labels, tr_size, sigma, lam, num_cv):\n",
    "    errors = []\n",
    "    for cv in range(num_cv):\n",
    "        reps_tr, reps_test, labels_tr, labels_test = sk.train_test_split(reps,labels,train_size=tr_size)\n",
    "        coeffs = qmi.train_kernel(reps_tr, labels_tr, sigma, lam_val)\n",
    "        labels_predicted = qmi.predict_labels(reps_test, reps_tr, sigma, coeffs)\n",
    "        errors.append((np.abs(labels_predicted - labels_test)).mean())\n",
    "    errors = np.array(errors)\n",
    "    return(errors.mean(), errors.std())\n",
    "\n",
    "def save_obj(obj, fname ):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def get_tr_size(data_size):\n",
    "    \"\"\"\n",
    "    largest number of training points is roughly 90% of complete data (largest multiple of 2 that is <= 90%)\n",
    "    \"\"\"\n",
    "    largest_set = int(np.log2(data_size*0.9))\n",
    "    tr_size = np.logspace(0, largest_set, largest_set+1, base=2).astype(int)\n",
    "    return(tr_size)\n",
    "\n",
    "def get_element_symbol(Z):\n",
    "    if int(Z) == 1:\n",
    "        return('H')\n",
    "    elif int(Z) == 6:\n",
    "        return('C')\n",
    "    elif int(Z) == 7:\n",
    "        return('N')\n",
    "    elif int(Z) == 8:\n",
    "        return('O')\n",
    "    else:\n",
    "        raise ValueError('Symbol for given charge not available')\n",
    "        \n",
    "# data preparation\n",
    "data, molecule_size = qmi.load_alchemy_data(qmi.wrapper_alch_data())\n",
    "alch_pots = qmi.generate_label_vector(data, molecule_size.sum(), value='alch_pot')\n",
    "\n",
    "all_local_reps = get_aslatm(data, molecule_size)\n",
    "\n",
    "# split up alchemical potential by element\n",
    "charges = qmi.generate_label_vector(data, molecule_size.sum(), value='charge')\n",
    "idc_by_charge = qmi.partition_idx_by_charge(charges)\n",
    "\n",
    "el_reps =dict()\n",
    "el_alch_pots = dict()\n",
    "for k in idc_by_charge.keys():\n",
    "    el_reps[k] = all_local_reps[idc_by_charge[k]]\n",
    "    el_alch_pots[k] = alch_pots[idc_by_charge[k]]\n",
    "    \n",
    "sigmas = np.logspace(-6, 10, 11, base=2)#np.logspace(-1, 10, 11, base=2) # np.logspace(-6, -2, 5, base=2)\n",
    "lam_val = 1e-3\n",
    "num_cv = 3\n",
    "\n",
    "for charge in el_reps.keys():\n",
    "    lcurves = dict()\n",
    "\n",
    "    # define number of training points for which MAE is calculated\n",
    "    set_sizes = get_tr_size(len(el_alch_pots[charge]))\n",
    "    \n",
    "    # special for H\n",
    "#     set_sizes = np.concatenate((set_sizes, np.array([3300])))\n",
    "\n",
    "    for sigma in sigmas:\n",
    "        error_cv = []\n",
    "        error_std = []\n",
    "        # calculate error for every training point size\n",
    "        for idx, tr_size in enumerate(set_sizes):\n",
    "            err, err_std = crossvalidate(el_reps[charge], el_alch_pots[charge], tr_size, sigma, lam_val, num_cv)\n",
    "            error_cv.append(err)\n",
    "            error_std.append(err_std)\n",
    "\n",
    "        lcurves[f'sig_{sigma}'] = np.array([set_sizes, error_cv, error_std]).T\n",
    "        \n",
    "    \n",
    "    # save best learning curve\n",
    "    lowest_error = (None, None)\n",
    "    for k in lcurves.keys():\n",
    "        if lowest_error[1]==None or lowest_error[1] > np.amin(lcurves[k][:,1]):\n",
    "            lowest_error = (k, np.amin(lcurves[k][:,1]))\n",
    "    save_data = lcurves[lowest_error[0]]\n",
    "\n",
    "    # filename\n",
    "    el_symbol = get_element_symbol(charge)\n",
    "    path = f'/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/best_alchpots_large_lambda_sigma_{el_symbol}.txt'\n",
    "\n",
    "    sig_val = lowest_error[0].split('_')[1]\n",
    "    header = f'sigma = {sig_val}, lambda = {lam_val}, number cv = {num_cv}'\n",
    "    np.savetxt(path, save_data, delimiter='\\t', header=header)\n",
    "\n",
    "    # save dictionary of learning curves at all sigmas\n",
    "    fname = f'/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/aslatm/large_lambda_all_sigma_alchpots_{el_symbol}.txt'\n",
    "    save_obj(lcurves, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if conversion from list of np-arrays to np-array was carried out correctly\n",
    "a = 0\n",
    "for j in range(len(reps)):\n",
    "    for i in range(molecule_size[j]):\n",
    "        a += (reps[j][i] - full_reps[molecule_size[0:j].sum()+i]).sum()\n",
    "print(a)\n",
    "print(len(reps[0])+len(reps[1])+len(reps[2]))\n",
    "print((reps[3][2] - full_reps[56]).sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:atomic-energies]",
   "language": "python",
   "name": "conda-env-atomic-energies-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
