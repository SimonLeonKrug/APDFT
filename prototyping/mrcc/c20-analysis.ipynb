{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read list of nuclear charges, give energy predictions up to nth order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import qml\n",
    "import scipy.spatial as scs\n",
    "import scipy.interpolate as sci\n",
    "import functools\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = qml.Compound('../../test/c20.xyz')\n",
    "def _get_nn(refsite):\n",
    "    distances = np.linalg.norm(c.coordinates - c.coordinates[refsite], axis=1)\n",
    "    return np.argsort(distances)[1:4]\n",
    "def build_reindexing_1_merged(refsite, ontosite):\n",
    "    cog = np.mean(c.coordinates, axis=0)\n",
    "    valid = False\n",
    "    for Ann in _get_nn(refsite):\n",
    "        for Bnn in _get_nn(ontosite):\n",
    "            A = c.coordinates[[refsite, Ann]]\n",
    "            B = c.coordinates[[ontosite, Bnn]]\n",
    "            rot = scs.transform.Rotation.match_vectors(A, B)[0]\n",
    "            transformed = rot.apply(c.coordinates)\n",
    "            found = []\n",
    "            for site in range(len(c.coordinates)):\n",
    "                ds = np.linalg.norm(transformed - c.coordinates[site], axis=1)\n",
    "                if min(ds) < 1e-5:\n",
    "                    found.append(np.argmin(ds))\n",
    "            if set(found) == set([_ for _ in range(len(c.coordinates))]) and found[refsite] == ontosite:\n",
    "                valid = True\n",
    "                break\n",
    "        if valid:\n",
    "            break\n",
    "    if not valid:\n",
    "        raise ValueError('no solution')\n",
    "    return found\n",
    "\n",
    "def read_DENSITY(fn):\n",
    "    with open(fn, 'r') as fh:\n",
    "        _ = np.fromfile(fh, 'i4')\n",
    "        q = _[3:-1].view(np.float64)\n",
    "        ccdensity = q.reshape((-1, 10))\n",
    "    ccdensity = ccdensity[:, 1:6]\n",
    "    return ccdensity[:, :3]/1.8897259885789, ccdensity[:, 3], ccdensity[:, 4]\n",
    "\n",
    "def read_grid_first_order():\n",
    "    changed_site = 0\n",
    "    delta = 0.1\n",
    "    \n",
    "    upgrid, upweight, updens = read_DENSITY_cached('c20-data/derivatives/order-1/site-0-up/DENSITY')\n",
    "    dngrid, dnweight, dndens = read_DENSITY_cached('c20-data/derivatives/order-1/site-0-dn/DENSITY')\n",
    "    \n",
    "    if not np.allclose(upgrid, dngrid):\n",
    "        raise ValueError('Grid?')\n",
    "        \n",
    "    if not np.allclose(upweight, dnweight):\n",
    "        raise ValueError('Grid?')\n",
    "    \n",
    "    return changed_site, upgrid, ((updens - dndens) / delta)*upweight\n",
    "def get_nucnuc(zs):\n",
    "    ds = scs.distance.squareform(scs.distance.pdist(c.coordinates))*1.8897259885789\n",
    "    q = np.outer(zs, zs)/ds\n",
    "    np.fill_diagonal(q, 0)\n",
    "    return q.sum()/2    \n",
    "def get_deriv(i, j):\n",
    "    \"\"\" Returns \n",
    "    t_i : atom index of i after rotation\n",
    "    t_j : atom index of j after rotation\n",
    "    deriv_pair : the density to be integrated after pairwise rotation\n",
    "    deriv_single : density to be integrated after single rotation \"\"\"\n",
    "    \n",
    "    d = np.linalg.norm(c.coordinates[i] - c.coordinates[j])\n",
    "    geo = np.argmin(np.abs(np.array(sorted(set(np.round(scs.distance.pdist(c.coordinates), 2)))) - d))\n",
    "    sites = (0, (1, 2, 8, 10, 16)[geo])\n",
    "    i, j = sites\n",
    "    delta = 0.1\n",
    "    \n",
    "    assert i == 0\n",
    "    midgrid, midweight, middens = read_DENSITY_cached('c20-data/derivatives/order-0/site-all-cc/DENSITY')\n",
    "    # prefill output\n",
    "    deriv_single = np.zeros(middens.shape)\n",
    "    deriv_pair = np.zeros(middens.shape)\n",
    "    \n",
    "    iupgrid, iupweight, iupdens = read_DENSITY_cached('c20-data/derivatives/order-1/site-0-up/DENSITY')\n",
    "    idngrid, idnweight, idndens = read_DENSITY_cached('c20-data/derivatives/order-1/site-0-dn/DENSITY')\n",
    "    if i == j:\n",
    "        deriv_single = (iupdens + idndens - 2 * middens)/(delta**2)\n",
    "    else:\n",
    "        rhojup = iupdens\n",
    "        rhojdn = idndens\n",
    "        upgrid, upweight, updens = read_DENSITY_cached('c20-data/derivatives/order-2/site-0-%d-up/DENSITY' % j)\n",
    "        dngrid, dnweight, dndens = read_DENSITY_cached('c20-data/derivatives/order-2/site-0-%d-dn/DENSITY' % j)\n",
    "        \n",
    "        deriv_pair = (updens + dndens + 2 * middens - iupdens - idndens) / (2 * delta**2)\n",
    "        deriv_single = (- rhojup - rhojdn) / (2 * delta**2)\n",
    "    \n",
    "    return i, j, deriv_pair * midweight, deriv_single * midweight\n",
    "def build_reindexing_2_merged(refsite1, refsite2, ontosite1, ontosite2):\n",
    "    if refsite1 == ontosite1 and refsite2 == ontosite2:\n",
    "        return list(range(20))\n",
    "    for inverse in (True, False):\n",
    "        for asc in (True, False):\n",
    "            for mirror in (True, False):\n",
    "                for mirrorafter in (True, False):\n",
    "                    for noflip in (True, False):\n",
    "                        for rotate60 in (True, False):\n",
    "                            for rotate90 in (True, False):\n",
    "                                for reflectrotate in (True, False):\n",
    "                                    for rotate120 in (True, False):\n",
    "                                        try:\n",
    "                                            return do_it(refsite1, refsite2, ontosite1, ontosite2, inverse, asc, mirror, mirrorafter, noflip, rotate60, rotate90, reflectrotate, rotate120)\n",
    "                                        except ValueError:\n",
    "                                            continue\n",
    "    raise ValueError('No luck.')\n",
    "def do_it(refsite1, refsite2, ontosite1, ontosite2, inverse, asc, mirror, mirrorafter, noflip, rotate60, rotate90, reflectrotate,rotate120):\n",
    "    #print (inverse, asc, mirror, mirrorafter, noflip,rotate60, rotate90)\n",
    "    valid = False\n",
    "    if inverse:\n",
    "        coordinates = np.copy(c.coordinates)*(-1)\n",
    "    else:\n",
    "        coordinates = np.copy(c.coordinates)\n",
    "    \n",
    "    A = c.coordinates[[refsite1, refsite2]]\n",
    "    B = coordinates[[ontosite1, ontosite2]]\n",
    "    \n",
    "    if rotate60:\n",
    "        a = B[0] -B[1]\n",
    "        a = a/np.linalg.norm(a)*(np.pi/3)\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        coordinates = rot.apply(coordinates)\n",
    "    if rotate90:\n",
    "        a = B[0] -B[1]\n",
    "        a = a/np.linalg.norm(a)*(np.pi/4)\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        coordinates = rot.apply(coordinates)\n",
    "    if rotate120:\n",
    "        a = B[0] -B[1]\n",
    "        a = a/np.linalg.norm(a)*(2*np.pi/3)\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        coordinates = rot.apply(coordinates)\n",
    "    if mirror:\n",
    "        ax1 = A.sum(axis=0)\n",
    "        ax2 = B.sum(axis=0)\n",
    "        a = ax1 - ax2\n",
    "        for site in range(20):\n",
    "            v = coordinates[site].copy()\n",
    "            coordinates[site] = v- 2*a*np.dot(v, a) / np.dot(a, a)\n",
    "        transformed = coordinates\n",
    "    else:\n",
    "        A = c.coordinates[[refsite1, refsite2]]\n",
    "        B = coordinates[[ontosite1, ontosite2]]\n",
    "        #print (np.linalg.norm(c.coordinates[[refsite1, refsite2]] - coordinates[[ontosite1, ontosite2]] , axis=1))\n",
    "        if asc:\n",
    "            index = 0\n",
    "        else:\n",
    "            index = 1\n",
    "\n",
    "        # rotate first\n",
    "        a = np.cross(A[index], (0,0,1))\n",
    "        b = np.cross(B[index], (0, 0, 1))\n",
    "        rot = scs.transform.Rotation.match_vectors([A[index], a], [B[index], b])[0]\n",
    "        transformed = rot.apply(c.coordinates)\n",
    "        #print (np.linalg.norm(c.coordinates[[refsite1, refsite2]] - transformed[[ontosite1, ontosite2]] , axis=1))\n",
    "\n",
    "        # rotate second\n",
    "        A = c.coordinates[[refsite1, refsite2]]\n",
    "        B = transformed[[ontosite1, ontosite2]]\n",
    "        rot = scs.transform.Rotation.match_vectors(A, B)[0]\n",
    "        transformed2 = rot.apply(transformed)\n",
    "        transformed = transformed2\n",
    "        #print (np.linalg.norm(c.coordinates[[refsite1, refsite2]] - transformed[[ontosite1, ontosite2]] , axis=1))\n",
    "        if max(np.linalg.norm(c.coordinates[[refsite1, refsite2]] - transformed[[ontosite1, ontosite2]] , axis=1)) > 1e-5:\n",
    "            raise ValueError('no rotation')\n",
    "    \n",
    "    if mirrorafter:\n",
    "        a = transformed[ontosite1] - transformed[ontosite2]\n",
    "        for site in range(20):\n",
    "            v = transformed[site].copy()\n",
    "            transformed[site] = v- 2*a*np.dot(v, a) / np.dot(a, a)\n",
    "    if noflip:      \n",
    "        a = transformed[ontosite1] + transformed[ontosite2]\n",
    "        a = a/np.linalg.norm(a)*np.pi\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        transformed = rot.apply(transformed)\n",
    "        #print (np.linalg.norm(c.coordinates[[refsite1, refsite2]] - transformed[[ontosite1, ontosite2]] , axis=1))\n",
    "    \n",
    "    if reflectrotate:\n",
    "        a = transformed[ontosite1] - transformed[ontosite2]\n",
    "        for site in range(20):\n",
    "            v = transformed[site].copy()\n",
    "            transformed[site] = v- 2*a*np.dot(v, a) / np.dot(a, a)\n",
    "        a = a/np.linalg.norm(a)*(np.pi)\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        transformed = rot.apply(transformed)\n",
    "    found = []\n",
    "    for site in range(len(c.coordinates)):\n",
    "        ds = np.linalg.norm(transformed - c.coordinates[site], axis=1)\n",
    "        if min(ds) < 1e-5:\n",
    "            #print (site, np.argmin(ds))\n",
    "            found.append(np.argmin(ds))\n",
    "    #try:\n",
    "    #    print (set(found))#, found[refsite1], ontosite1, found[refsite2], ontosite2)\n",
    "    #except:\n",
    "    #    pass\n",
    "    if set(found) == set([_ for _ in range(len(c.coordinates))]) and found[refsite1] == ontosite1 and found[refsite2] == ontosite2:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('no solution')\n",
    "    return found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=20*20*20*20)\n",
    "def build_reindexing_2_cached(a, b, c, d):\n",
    "    return build_reindexing_2_merged(a, b, c,d)\n",
    "@functools.lru_cache(maxsize=20*20*20*20)\n",
    "def build_reindexing_1_cached(a, b):\n",
    "    return build_reindexing_1_merged(a, b)\n",
    "@functools.lru_cache(200)\n",
    "def read_DENSITY_cached(fn):\n",
    "    return read_DENSITY(fn)\n",
    "@functools.lru_cache(30)\n",
    "def get_grid_ds(j):\n",
    "    return 1/(np.linalg.norm(grid_points - c.coordinates[j], axis=1)*1.8897259885789)\n",
    "@functools.lru_cache(maxsize=20*20)\n",
    "def get_deriv_cached(i, j):\n",
    "    return get_deriv(i, j)\n",
    "changed_site, grid_points, grid_densweight = read_grid_first_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# warm caches\n",
    "def test_all_pairs(n):\n",
    "    ds = scs.distance.squareform(scs.distance.pdist(c.coordinates))\n",
    "    dvals = np.unique(np.round(ds, 2))\n",
    "    xs, ys = np.where(abs(ds - dvals[n])< 0.1)\n",
    "    tosites = (0,1, 2, 8, 10, 16)[n]\n",
    "    for i, j in zip(xs, ys):\n",
    "        if i == j:\n",
    "            continue\n",
    "        try:\n",
    "            build_reindexing_2_merged(i, j, 0, tosites)\n",
    "        except:\n",
    "            print (i, j, 0, tosites)\n",
    "for i in range(6):\n",
    "    print (i)\n",
    "    test_all_pairs(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guido/miniconda3/envs/analysis/lib/python3.6/site-packages/ipykernel_launcher.py:52: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn -1.3720936347899624\n",
      "f -0.15746451062763975\n",
      "s -12.90398317590783\n",
      "-14.433541321325432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 6.33456 s\n",
       "File: <ipython-input-13-36f22db99b40>\n",
       "Function: get_predictions at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def get_predictions(comb):\n",
       "     2                                               #rho, dsingle, dneigh1, dneigh2, dneigh3, dneigh4, dneigh5 = read_densities()\n",
       "     3                                                   \n",
       "     4         1          8.0      8.0      0.0      E =0#-758.072029908548 # base energy\n",
       "     5         1         44.0     44.0      0.0      deltaZ = np.array(comb) - 6\n",
       "     6                                                   \n",
       "     7         1         40.0     40.0      0.0      zs = np.array([int(_) for _ in comb])\n",
       "     8         1         25.0     25.0      0.0      zsref = np.zeros(20) + 6\n",
       "     9                                               \n",
       "    10         1       1030.0   1030.0      0.0      E -= get_nucnuc(zsref)\n",
       "    11         1        706.0    706.0      0.0      E += get_nucnuc(zs)\n",
       "    12         1        346.0    346.0      0.0      print ('nn', E)\n",
       "    13                                               \n",
       "    14                                               # 0-th order, no rotation necessary, should be hard zero\n",
       "    15                                               #ds = np.linalg.norm(grid_points - c.coordinates[0], axis=1)\n",
       "    16                                               #es = (rho * grid_weights / ds).sum()\n",
       "    17                                               #for idx, Z in enumerate(comb):\n",
       "    18                                               #    if deltaZ[idx] == 0:\n",
       "    19                                               #        continue\n",
       "    20                                               #    E += np.sum(deltaZ[idx] * rho * grid_weights / ds)\n",
       "    21                                               \n",
       "    22                                               # 1st order\n",
       "    23         1     142178.0 142178.0      2.2      changed_site, grid_points, grid_densweight = read_grid_first_order()\n",
       "    24         1        393.0    393.0      0.0      dV = np.zeros(grid_densweight.shape)\n",
       "    25        21        164.0      7.8      0.0      for idx, Z in enumerate(comb):\n",
       "    26        20        219.0     10.9      0.0          if deltaZ[idx] == 0:\n",
       "    27         8         60.0      7.5      0.0              continue\n",
       "    28        12        115.0      9.6      0.0          mapping = build_reindexing_1_cached(idx, changed_site)\n",
       "    29                                                   \n",
       "    30       252       2399.0      9.5      0.0          for j in range(20): \n",
       "    31       240       2893.0     12.1      0.0              if deltaZ[mapping[j]] == 0:\n",
       "    32        96        625.0      6.5      0.0                  continue\n",
       "    33       144       1443.0     10.0      0.0              ds = get_grid_ds(j)\n",
       "    34       144     246463.0   1711.5      3.9              dV += deltaZ[idx] * deltaZ[mapping[j]]* ds\n",
       "    35                                                       #E += np.sum(deltaZ[idx] * deltaZ[mapping[j]] * grid_densweight / ds)/2\n",
       "    36         1       2396.0   2396.0      0.0      f = -np.sum(dV * grid_densweight)/2\n",
       "    37         1        530.0    530.0      0.0      print ('f', f)\n",
       "    38         1         11.0     11.0      0.0      E += f\n",
       "    39                                               \n",
       "    40                                               # 2nd order\n",
       "    41         1          9.0      9.0      0.0      del dV, idx\n",
       "    42         1       1143.0   1143.0      0.0      dE = np.zeros(grid_densweight.shape)\n",
       "    43        21        132.0      6.3      0.0      for idx_i, Z_i in enumerate(comb):\n",
       "    44        20        345.0     17.2      0.0          if deltaZ[idx_i] == 0:\n",
       "    45         8         74.0      9.2      0.0              continue\n",
       "    46       252       2161.0      8.6      0.0          for idx_j, Z_j in enumerate(comb):\n",
       "    47       240       3372.0     14.1      0.1              if deltaZ[idx_j] == 0:\n",
       "    48        96        602.0      6.3      0.0                  continue\n",
       "    49                                                       \n",
       "    50                                                       # t_i: target for idx_i after rotation\n",
       "    51                                                       # deriv_pair: part of derivative after pair-mapping\n",
       "    52                                                       # deriv_single: part of derivative after single-mapping\n",
       "    53       144       1729.0     12.0      0.0              t_i, t_j, deriv_pair, deriv_single = get_deriv_cached(idx_i, idx_j)\n",
       "    54                                                       \n",
       "    55                                                       # pairwise mapping\n",
       "    56       144        875.0      6.1      0.0              q = 0\n",
       "    57       144       1025.0      7.1      0.0              if idx_i != idx_j:\n",
       "    58       132        898.0      6.8      0.0                  try:\n",
       "    59       132       1342.0     10.2      0.0                      mapping = build_reindexing_2_cached(idx_i, idx_j, t_i, t_j)\n",
       "    60                                                           except:\n",
       "    61                                                               print (idx_i, idx_j, t_i, t_j)\n",
       "    62      2772      23524.0      8.5      0.4                  for j in range(20): \n",
       "    63      2640      38763.0     14.7      0.6                      if deltaZ[mapping[j]] == 0:\n",
       "    64      1056       6524.0      6.2      0.1                          continue\n",
       "    65      1584      16805.0     10.6      0.3                      ds = get_grid_ds(j)\n",
       "    66      1584    2564199.0   1618.8     40.5                      q += (deltaZ[idx_i] *deltaZ[idx_j] * deltaZ[mapping[j]]) * ds\n",
       "    67       132     242260.0   1835.3      3.8                  dE += q * deriv_pair\n",
       "    68       132       1964.0     14.9      0.0                  del q\n",
       "    69                                                       \n",
       "    70                                                       # single mapping\n",
       "    71       144       1637.0     11.4      0.0              mapping = build_reindexing_1_cached(idx_j, 0)\n",
       "    72       144       1106.0      7.7      0.0              q = 0\n",
       "    73      3024      26616.0      8.8      0.4              for j in range(20): \n",
       "    74      2880      36965.0     12.8      0.6                  if deltaZ[mapping[j]] == 0:\n",
       "    75      1152       7189.0      6.2      0.1                      continue\n",
       "    76      1728      18387.0     10.6      0.3                  ds = get_grid_ds(j)\n",
       "    77      1728    2672595.0   1546.6     42.2                  q += (deltaZ[idx_i] * deltaZ[idx_j] * deltaZ[mapping[j]]) * ds\n",
       "    78       144     257106.0   1785.5      4.1              dE += q*deriv_single\n",
       "    79       144       1624.0     11.3      0.0              del q\n",
       "    80         1        763.0    763.0      0.0      s = -np.sum(dE)/6\n",
       "    81         1        718.0    718.0      0.0      print ('s', s)\n",
       "    82         1         15.0     15.0      0.0      E += s\n",
       "    83                                                       \n",
       "    84         1          7.0      7.0      0.0      return E"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_predictions(comb):\n",
    "    #rho, dsingle, dneigh1, dneigh2, dneigh3, dneigh4, dneigh5 = read_densities()\n",
    "        \n",
    "    E =0#-758.072029908548 # base energy\n",
    "    deltaZ = np.array(comb) - 6\n",
    "        \n",
    "    zs = np.array([int(_) for _ in comb])\n",
    "    zsref = np.zeros(20) + 6\n",
    "    \n",
    "    E -= get_nucnuc(zsref)\n",
    "    E += get_nucnuc(zs)\n",
    "    print ('nn', E)\n",
    "    \n",
    "    # 0-th order, no rotation necessary, should be hard zero\n",
    "    #ds = np.linalg.norm(grid_points - c.coordinates[0], axis=1)\n",
    "    #es = (rho * grid_weights / ds).sum()\n",
    "    #for idx, Z in enumerate(comb):\n",
    "    #    if deltaZ[idx] == 0:\n",
    "    #        continue\n",
    "    #    E += np.sum(deltaZ[idx] * rho * grid_weights / ds)\n",
    "    \n",
    "    # 1st order\n",
    "    changed_site, grid_points, grid_densweight = read_grid_first_order()\n",
    "    dV = np.zeros(grid_densweight.shape)\n",
    "    for idx, Z in enumerate(comb):\n",
    "        if deltaZ[idx] == 0:\n",
    "            continue\n",
    "        mapping = build_reindexing_1_cached(idx, changed_site)\n",
    "        \n",
    "        for j in range(20): \n",
    "            if deltaZ[mapping[j]] == 0:\n",
    "                continue\n",
    "            ds = get_grid_ds(j)\n",
    "            dV += deltaZ[idx] * deltaZ[mapping[j]]* ds\n",
    "            #E += np.sum(deltaZ[idx] * deltaZ[mapping[j]] * grid_densweight / ds)/2\n",
    "    f = -np.sum(dV * grid_densweight)/2\n",
    "    print ('f', f)\n",
    "    E += f\n",
    "    \n",
    "    # 2nd order\n",
    "    del dV, idx\n",
    "    dE = np.zeros(grid_densweight.shape)\n",
    "    for idx_i, Z_i in enumerate(comb):\n",
    "        if deltaZ[idx_i] == 0:\n",
    "            continue\n",
    "        for idx_j, Z_j in enumerate(comb):\n",
    "            if deltaZ[idx_j] == 0:\n",
    "                continue\n",
    "            \n",
    "            # t_i: target for idx_i after rotation\n",
    "            # deriv_pair: part of derivative after pair-mapping\n",
    "            # deriv_single: part of derivative after single-mapping\n",
    "            t_i, t_j, deriv_pair, deriv_single = get_deriv_cached(idx_i, idx_j)\n",
    "            \n",
    "            # pairwise mapping\n",
    "            if idx_i != idx_j:\n",
    "                q = 0\n",
    "                try:\n",
    "                    mapping = build_reindexing_2_cached(idx_i, idx_j, t_i, t_j)\n",
    "                except:\n",
    "                    print (idx_i, idx_j, t_i, t_j)\n",
    "                for j in range(20): \n",
    "                    if deltaZ[mapping[j]] == 0:\n",
    "                        continue\n",
    "                    ds = get_grid_ds(j)\n",
    "                    q += (deltaZ[idx_i] *deltaZ[idx_j] * deltaZ[mapping[j]]) * ds\n",
    "                dE += q * deriv_pair\n",
    "                del q\n",
    "            \n",
    "            # single mapping\n",
    "            mapping = build_reindexing_1_cached(idx_j, 0)\n",
    "            q = 0\n",
    "            for j in range(20): \n",
    "                if deltaZ[mapping[j]] == 0:\n",
    "                    continue\n",
    "                ds = get_grid_ds(j)\n",
    "                q += (deltaZ[idx_i] * deltaZ[idx_j] * deltaZ[mapping[j]]) * ds\n",
    "            dE += q*deriv_single\n",
    "            del q\n",
    "    s = -np.sum(dE)/6\n",
    "    print ('s', s)\n",
    "    E += s\n",
    "            \n",
    "    return E\n",
    "%lprun -f get_predictions print (get_predictions([int(_) for _ in '57766576666555776675']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guido/miniconda3/envs/analysis/lib/python3.6/site-packages/ipykernel_launcher.py:52: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn 3.44556140059899\n",
      "f -10.575711364660142\n",
      "s -0.12615130490374327\n",
      "-7.256301268964895\n",
      "CPU times: user 42.8 s, sys: 500 ms, total: 43.3 s\n",
      "Wall time: 26.3 s\n"
     ]
    }
   ],
   "source": [
    "%time print (get_predictions([int(_) for _ in '55555555557777777777']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symbolic solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: only limited amount of input densities. Skip intermediate evaluations, merge at the end, have products pre-computed. Use cached atom mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNS = '''c20-data/derivatives/order-0/site-all-cc/DENSITY\n",
    "c20-data/derivatives/order-1/site-0-dn/DENSITY\n",
    "c20-data/derivatives/order-1/site-0-up/DENSITY\n",
    "c20-data/derivatives/order-2/site-0-1-dn/DENSITY\n",
    "c20-data/derivatives/order-2/site-0-1-up/DENSITY\n",
    "c20-data/derivatives/order-2/site-0-10-dn/DENSITY\n",
    "c20-data/derivatives/order-2/site-0-10-up/DENSITY\n",
    "c20-data/derivatives/order-2/site-0-16-dn/DENSITY\n",
    "c20-data/derivatives/order-2/site-0-16-up/DENSITY\n",
    "c20-data/derivatives/order-2/site-0-2-dn/DENSITY\n",
    "c20-data/derivatives/order-2/site-0-2-up/DENSITY\n",
    "c20-data/derivatives/order-2/site-0-8-dn/DENSITY\n",
    "c20-data/derivatives/order-2/site-0-8-up/DENSITY'''.split('\\n')\n",
    "def symbolic_read_density(fn):\n",
    "    return FNS.index(fn)\n",
    "@functools.lru_cache(maxsize=20*20)\n",
    "def symbolic_get_deriv(i, j):\n",
    "    \"\"\" Returns \n",
    "    t_i : atom index of i after rotation\n",
    "    t_j : atom index of j after rotation\n",
    "    deriv_pair : the density to be integrated after pairwise rotation\n",
    "    deriv_single : density to be integrated after single rotation \"\"\"\n",
    "    \n",
    "    d = np.linalg.norm(c.coordinates[i] - c.coordinates[j])\n",
    "    geo = np.argmin(np.abs(np.array(sorted(set(np.round(scs.distance.pdist(c.coordinates), 2)))) - d))\n",
    "    sites = (0, (1, 2, 8, 10, 16)[geo])\n",
    "    i, j = sites\n",
    "    delta = 0.1\n",
    "    deriv_single = np.zeros(13)\n",
    "    deriv_pair = np.zeros(13)\n",
    "    \n",
    "    mid = symbolic_read_density('c20-data/derivatives/order-0/site-all-cc/DENSITY')\n",
    "    iup = symbolic_read_density('c20-data/derivatives/order-1/site-0-up/DENSITY')\n",
    "    idn = symbolic_read_density('c20-data/derivatives/order-1/site-0-dn/DENSITY')\n",
    "    if i == j:\n",
    "        deriv_single[iup] = 1/(delta**2)\n",
    "        deriv_single[idn] = 1/(delta**2)\n",
    "        deriv_single[mid] = -2/(delta**2)\n",
    "    else:\n",
    "        jup = iup\n",
    "        jdn = idn\n",
    "        up = symbolic_read_density('c20-data/derivatives/order-2/site-0-%d-up/DENSITY' % j)\n",
    "        dn = symbolic_read_density('c20-data/derivatives/order-2/site-0-%d-dn/DENSITY' % j)\n",
    "        \n",
    "        deriv_pair[up] = 1/ (2 * delta**2)\n",
    "        deriv_pair[dn] = 1/ (2 * delta**2)\n",
    "        deriv_pair[mid] = 2/ (2 * delta**2)\n",
    "        deriv_pair[iup] = -1/ (2 * delta**2)\n",
    "        deriv_pair[idn] = -1/ (2 * delta**2)\n",
    "        \n",
    "        deriv_single[jup] = -1/ (2 * delta**2)\n",
    "        deriv_single[jdn] = -1/ (2 * delta**2)\n",
    "    \n",
    "    return i, j, deriv_pair/6, deriv_single/6\n",
    "def symbolic_read_grid_first_order():\n",
    "    changed_site = 0\n",
    "    delta = 0.1\n",
    "    \n",
    "    up = symbolic_read_density('c20-data/derivatives/order-1/site-0-up/DENSITY')\n",
    "    dn = symbolic_read_density('c20-data/derivatives/order-1/site-0-dn/DENSITY')\n",
    "    deriv_single = np.zeros(13)\n",
    "    deriv_single[up] = 1/delta\n",
    "    deriv_single[dn] = -1/delta\n",
    "    \n",
    "    return changed_site, deriv_single/2\n",
    "def coefficient_matrix():\n",
    "    result = np.zeros((20, 13))\n",
    "    for fidx, fn in enumerate(FNS):\n",
    "        _, a, b = read_DENSITY_cached(fn)\n",
    "        for j in range(20):\n",
    "            ds = get_grid_ds(j)\n",
    "            result[j, fidx] = (a*b*ds).sum()\n",
    "    return result\n",
    "COEFFMAT = coefficient_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'order0': -758.072029908548, 'deltaNN': -1.3720936347899624, 'order1': 0.0, 'order2': -0.157464510626653, 'order3': -12.90398317589279, 'prediction': -772.5055712298574, 'target': '57766576666555776675'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guido/miniconda3/envs/analysis/lib/python3.6/site-packages/ipykernel_launcher.py:52: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.043196 s\n",
       "File: <ipython-input-99-753ee4fc13ad>\n",
       "Function: symbolic_get_predictions at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def symbolic_get_predictions(comb):\n",
       "     2                                               #rho, dsingle, dneigh1, dneigh2, dneigh3, dneigh4, dneigh5 = read_densities()\n",
       "     3                                                   \n",
       "     4         1          7.0      7.0      0.0      result = {}\n",
       "     5         1          6.0      6.0      0.0      result['order0'] = -758.072029908548\n",
       "     6                                               \n",
       "     7         1         38.0     38.0      0.1      deltaZ = np.array(comb) - 6\n",
       "     8                                                   \n",
       "     9         1         31.0     31.0      0.1      zs = np.array([int(_) for _ in comb])\n",
       "    10         1         22.0     22.0      0.1      zsref = np.zeros(20) + 6\n",
       "    11         1        933.0    933.0      2.2      result['deltaNN'] = get_nucnuc(zs) - get_nucnuc(zsref)\n",
       "    12                                               \n",
       "    13                                               # collect terms to evaluate, shape (density x atoms)\n",
       "    14         1          9.0      9.0      0.0      coefficients = np.zeros((20, 13))\n",
       "    15                                               \n",
       "    16                                               # 0-th order, no rotation necessary, should be hard zero\n",
       "    17         1          5.0      5.0      0.0      result['order1'] = 0.\n",
       "    18                                               \n",
       "    19                                               # 1st order\n",
       "    20         1         31.0     31.0      0.1      changed_site, this_coefficients = symbolic_read_grid_first_order()\n",
       "    21        21        125.0      6.0      0.3      for idx in range(20):\n",
       "    22        20        171.0      8.6      0.4          if deltaZ[idx] != 0:\n",
       "    23        12         78.0      6.5      0.2              mapping = build_reindexing_1_cached(idx, changed_site)\n",
       "    24        12        553.0     46.1      1.3              coefficients -= deltaZ[idx] * np.outer(deltaZ[mapping], this_coefficients)\n",
       "    25                                               \n",
       "    26         1         26.0     26.0      0.1      result['order2'] = np.multiply(coefficients,COEFFMAT).sum()\n",
       "    27                                               \n",
       "    28                                               # 2nd order\n",
       "    29         1         10.0     10.0      0.0      coefficients = np.zeros((20, 13))\n",
       "    30         1          8.0      8.0      0.0      outercache = np.zeros(coefficients.shape)\n",
       "    31        21        127.0      6.0      0.3      for idx_i in range(20):\n",
       "    32        20        142.0      7.1      0.3          if deltaZ[idx_i] != 0:\n",
       "    33       252       1621.0      6.4      3.8              for idx_j in range(20):\n",
       "    34       240       4763.0     19.8     11.0                  if deltaZ[idx_j] != 0:\n",
       "    35                                                               # t_i: target for idx_i after rotation\n",
       "    36                                                               # deriv_pair: part of derivative after pair-mapping\n",
       "    37                                                               # deriv_single: part of derivative after single-mapping\n",
       "    38       144       1120.0      7.8      2.6                      t_i, t_j, deriv_pair, deriv_single = symbolic_get_deriv(idx_i, idx_j)\n",
       "    39                                           \n",
       "    40                                                               # pairwise mapping\n",
       "    41       144        916.0      6.4      2.1                      if idx_i != idx_j:\n",
       "    42       132        935.0      7.1      2.2                          mapping = build_reindexing_2_cached(idx_i, idx_j, t_i, t_j)\n",
       "    43       132      17774.0    134.7     41.1                          np.outer(deltaZ[mapping], deriv_pair, out=outercache)\n",
       "    44       132       4385.0     33.2     10.2                          coefficients -= (deltaZ[idx_i] * deltaZ[idx_j]) * outercache\n",
       "    45                                           \n",
       "    46                                                               # single mapping\n",
       "    47       144       1075.0      7.5      2.5                      mapping = build_reindexing_1_cached(idx_j, 0)\n",
       "    48       144       5112.0     35.5     11.8                      np.outer(deltaZ[mapping], deriv_single, out=outercache)\n",
       "    49       144       3088.0     21.4      7.1                      coefficients -= (deltaZ[idx_i] * deltaZ[idx_j]) * outercache\n",
       "    50         1         34.0     34.0      0.1      result['order3'] = np.multiply(coefficients,COEFFMAT).sum()\n",
       "    51                                               \n",
       "    52         1         11.0     11.0      0.0      result['prediction'] = result['order0'] + result['order1'] + result['order2'] + result['order3'] + result['deltaNN']\n",
       "    53         1         35.0     35.0      0.1      result['target'] = ''.join([str(_) for _ in comb])\n",
       "    54                                               \n",
       "    55         1          5.0      5.0      0.0      return result"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def symbolic_get_predictions(comb):\n",
    "    #rho, dsingle, dneigh1, dneigh2, dneigh3, dneigh4, dneigh5 = read_densities()\n",
    "        \n",
    "    result = {}\n",
    "    result['order0'] = -758.072029908548\n",
    "    \n",
    "    deltaZ = np.array(comb) - 6\n",
    "        \n",
    "    zs = np.array([int(_) for _ in comb])\n",
    "    zsref = np.zeros(20) + 6\n",
    "    result['deltaNN'] = get_nucnuc(zs) - get_nucnuc(zsref)\n",
    "    \n",
    "    # collect terms to evaluate, shape (density x atoms)\n",
    "    coefficients = np.zeros((20, 13))\n",
    "    \n",
    "    # 0-th order, no rotation necessary, should be hard zero\n",
    "    result['order1'] = 0.\n",
    "    \n",
    "    # 1st order\n",
    "    changed_site, this_coefficients = symbolic_read_grid_first_order()\n",
    "    for idx in range(20):\n",
    "        if deltaZ[idx] != 0:\n",
    "            mapping = build_reindexing_1_cached(idx, changed_site)\n",
    "            coefficients -= deltaZ[idx] * np.outer(deltaZ[mapping], this_coefficients)\n",
    "    \n",
    "    result['order2'] = np.multiply(coefficients,COEFFMAT).sum()\n",
    "    \n",
    "    # 2nd order\n",
    "    coefficients = np.zeros((20, 13))\n",
    "    outercache = np.zeros(coefficients.shape)\n",
    "    for idx_i in range(20):\n",
    "        if deltaZ[idx_i] != 0:\n",
    "            for idx_j in range(20):\n",
    "                if deltaZ[idx_j] != 0:\n",
    "                    # t_i: target for idx_i after rotation\n",
    "                    # deriv_pair: part of derivative after pair-mapping\n",
    "                    # deriv_single: part of derivative after single-mapping\n",
    "                    t_i, t_j, deriv_pair, deriv_single = symbolic_get_deriv(idx_i, idx_j)\n",
    "\n",
    "                    # pairwise mapping\n",
    "                    if idx_i != idx_j:\n",
    "                        mapping = build_reindexing_2_cached(idx_i, idx_j, t_i, t_j)\n",
    "                        np.outer(deltaZ[mapping], deriv_pair, out=outercache)\n",
    "                        coefficients -= (deltaZ[idx_i] * deltaZ[idx_j]) * outercache\n",
    "\n",
    "                    # single mapping\n",
    "                    mapping = build_reindexing_1_cached(idx_j, 0)\n",
    "                    np.outer(deltaZ[mapping], deriv_single, out=outercache)\n",
    "                    coefficients -= (deltaZ[idx_i] * deltaZ[idx_j]) * outercache\n",
    "    result['order3'] = np.multiply(coefficients,COEFFMAT).sum()\n",
    "    \n",
    "    result['prediction'] = result['order0'] + result['order1'] + result['order2'] + result['order3'] + result['deltaNN']\n",
    "    result['target'] = ''.join([str(_) for _ in comb])\n",
    "    \n",
    "    return result\n",
    "%lprun -f symbolic_get_predictions print (symbolic_get_predictions([int(_) for _ in '57766576666555776675']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guido/miniconda3/envs/analysis/lib/python3.6/site-packages/ipykernel_launcher.py:52: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1 ms ± 344 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit symbolic_get_predictions([int(_) for _ in '57766576666555776675'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis]",
   "language": "python",
   "name": "conda-env-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
