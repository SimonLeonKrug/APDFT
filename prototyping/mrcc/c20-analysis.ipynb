{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read list of nuclear charges, give energy predictions up to nth order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import qml\n",
    "import scipy.spatial as scs\n",
    "import scipy.interpolate as sci\n",
    "import functools\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = qml.Compound('../../test/c20.xyz')\n",
    "def _get_nn(refsite):\n",
    "    distances = np.linalg.norm(c.coordinates - c.coordinates[refsite], axis=1)\n",
    "    return np.argsort(distances)[1:4]\n",
    "def build_reindexing_1_merged(refsite, ontosite):\n",
    "    cog = np.mean(c.coordinates, axis=0)\n",
    "    valid = False\n",
    "    for Ann in _get_nn(refsite):\n",
    "        for Bnn in _get_nn(ontosite):\n",
    "            A = c.coordinates[[refsite, Ann]]\n",
    "            B = c.coordinates[[ontosite, Bnn]]\n",
    "            rot = scs.transform.Rotation.match_vectors(A, B)[0]\n",
    "            transformed = rot.apply(c.coordinates)\n",
    "            found = []\n",
    "            for site in range(len(c.coordinates)):\n",
    "                ds = np.linalg.norm(transformed - c.coordinates[site], axis=1)\n",
    "                if min(ds) < 1e-5:\n",
    "                    found.append(np.argmin(ds))\n",
    "            if set(found) == set([_ for _ in range(len(c.coordinates))]) and found[refsite] == ontosite:\n",
    "                valid = True\n",
    "                break\n",
    "        if valid:\n",
    "            break\n",
    "    if not valid:\n",
    "        raise ValueError('no solution')\n",
    "    return found\n",
    "\n",
    "def read_DENSITY(fn):\n",
    "    with open(fn, 'r') as fh:\n",
    "        _ = np.fromfile(fh, 'i4')\n",
    "        q = _[3:-1].view(np.float64)\n",
    "        ccdensity = q.reshape((-1, 10))\n",
    "    ccdensity = ccdensity[:, 1:6]\n",
    "    return ccdensity[:, :3], ccdensity[:, 3], ccdensity[:, 4]\n",
    "\n",
    "def read_grid_first_order():\n",
    "    changed_site = 0\n",
    "    delta = 0.1\n",
    "    \n",
    "    upgrid, upweight, updens = read_DENSITY_cached('c20-data/derivatives/order-1/site-0-up/DENSITY')\n",
    "    dngrid, dnweight, dndens = read_DENSITY_cached('c20-data/derivatives/order-1/site-0-dn/DENSITY')\n",
    "    \n",
    "    if not np.allclose(upgrid, dngrid):\n",
    "        raise ValueError('Grid?')\n",
    "        \n",
    "    if not np.allclose(upweight, dnweight):\n",
    "        raise ValueError('Grid?')\n",
    "    \n",
    "    return changed_site, upgrid, ((updens - dndens) / delta)*upweight\n",
    "def get_nucnuc(zs):\n",
    "    ds = scs.distance.squareform(scs.distance.pdist(c.coordinates))*1.8897259885789\n",
    "    q = np.outer(zs, zs)/ds\n",
    "    np.fill_diagonal(q, 0)\n",
    "    return q.sum()/2    \n",
    "def get_deriv(i, j):\n",
    "    \"\"\" Returns \n",
    "    t_i : atom index of i after rotation\n",
    "    t_j : atom index of j after rotation\n",
    "    deriv_pair : the density to be integrated after pairwise rotation\n",
    "    deriv_single : density to be integrated after single rotation \"\"\"\n",
    "    \n",
    "    d = np.linalg.norm(c.coordinates[i] - c.coordinates[j])\n",
    "    geo = np.argmin(np.abs(np.array(sorted(set(np.round(scs.distance.pdist(c.coordinates), 2)))) - d))\n",
    "    sites = (0, (1, 2, 8, 10, 16)[geo])\n",
    "    i, j = sites\n",
    "    delta = 0.1\n",
    "    \n",
    "    assert i == 0\n",
    "    midgrid, midweight, middens = read_DENSITY_cached('c20-data/derivatives/order-0/site-all-cc/DENSITY')\n",
    "    # prefill output\n",
    "    deriv_single = np.zeros(middens.shape)\n",
    "    deriv_pair = np.zeros(middens.shape)\n",
    "    \n",
    "    iupgrid, iupweight, iupdens = read_DENSITY_cached('c20-data/derivatives/order-1/site-0-up/DENSITY')\n",
    "    idngrid, idnweight, idndens = read_DENSITY_cached('c20-data/derivatives/order-1/site-0-dn/DENSITY')\n",
    "    \n",
    "    if i == j:\n",
    "        deriv_single = (iupdens + idndens - 2 * middens)/(delta**2)\n",
    "    else:\n",
    "        rhojup = iupdens\n",
    "        rhojdn = idndens\n",
    "        upgrid, upweight, updens = read_DENSITY_cached('c20-data/derivatives/order-2/site-0-%d-up/DENSITY' % j)\n",
    "        dngrid, dnweight, dndens = read_DENSITY_cached('c20-data/derivatives/order-2/site-0-%d-dn/DENSITY' % j)\n",
    "        \n",
    "        deriv_pair = (updens + dndens + 2 * middens - iupdens - idndens) / (2 * delta**2)\n",
    "        deriv_single = (- rhojup - rhojdn) / (2 * delta**2)\n",
    "    \n",
    "    return i, j, deriv_pair, deriv_single\n",
    "def build_reindexing_2_merged(refsite1, refsite2, ontosite1, ontosite2):\n",
    "    if refsite1 == ontosite1 and refsite2 == ontosite2:\n",
    "        return list(range(20))\n",
    "    for inverse in (True, False):\n",
    "        for asc in (True, False):\n",
    "            for mirror in (True, False):\n",
    "                for mirrorafter in (True, False):\n",
    "                    for noflip in (True, False):\n",
    "                        for rotate60 in (True, False):\n",
    "                            for rotate90 in (True, False):\n",
    "                                for reflectrotate in (True, False):\n",
    "                                    for rotate120 in (True, False):\n",
    "                                        try:\n",
    "                                            return do_it(refsite1, refsite2, ontosite1, ontosite2, inverse, asc, mirror, mirrorafter, noflip, rotate60, rotate90, reflectrotate, rotate120)\n",
    "                                        except ValueError:\n",
    "                                            continue\n",
    "    raise ValueError('No luck.')\n",
    "def do_it(refsite1, refsite2, ontosite1, ontosite2, inverse, asc, mirror, mirrorafter, noflip, rotate60, rotate90, reflectrotate,rotate120):\n",
    "    #print (inverse, asc, mirror, mirrorafter, noflip,rotate60, rotate90)\n",
    "    valid = False\n",
    "    if inverse:\n",
    "        coordinates = np.copy(c.coordinates)*(-1)\n",
    "    else:\n",
    "        coordinates = np.copy(c.coordinates)\n",
    "    \n",
    "    A = c.coordinates[[refsite1, refsite2]]\n",
    "    B = coordinates[[ontosite1, ontosite2]]\n",
    "    \n",
    "    if rotate60:\n",
    "        a = B[0] -B[1]\n",
    "        a = a/np.linalg.norm(a)*(np.pi/3)\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        coordinates = rot.apply(coordinates)\n",
    "    if rotate90:\n",
    "        a = B[0] -B[1]\n",
    "        a = a/np.linalg.norm(a)*(np.pi/4)\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        coordinates = rot.apply(coordinates)\n",
    "    if rotate120:\n",
    "        a = B[0] -B[1]\n",
    "        a = a/np.linalg.norm(a)*(2*np.pi/3)\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        coordinates = rot.apply(coordinates)\n",
    "    if mirror:\n",
    "        ax1 = A.sum(axis=0)\n",
    "        ax2 = B.sum(axis=0)\n",
    "        a = ax1 - ax2\n",
    "        for site in range(20):\n",
    "            v = coordinates[site].copy()\n",
    "            coordinates[site] = v- 2*a*np.dot(v, a) / np.dot(a, a)\n",
    "        transformed = coordinates\n",
    "    else:\n",
    "        A = c.coordinates[[refsite1, refsite2]]\n",
    "        B = coordinates[[ontosite1, ontosite2]]\n",
    "        #print (np.linalg.norm(c.coordinates[[refsite1, refsite2]] - coordinates[[ontosite1, ontosite2]] , axis=1))\n",
    "        if asc:\n",
    "            index = 0\n",
    "        else:\n",
    "            index = 1\n",
    "\n",
    "        # rotate first\n",
    "        a = np.cross(A[index], (0,0,1))\n",
    "        b = np.cross(B[index], (0, 0, 1))\n",
    "        rot = scs.transform.Rotation.match_vectors([A[index], a], [B[index], b])[0]\n",
    "        transformed = rot.apply(c.coordinates)\n",
    "        #print (np.linalg.norm(c.coordinates[[refsite1, refsite2]] - transformed[[ontosite1, ontosite2]] , axis=1))\n",
    "\n",
    "        # rotate second\n",
    "        A = c.coordinates[[refsite1, refsite2]]\n",
    "        B = transformed[[ontosite1, ontosite2]]\n",
    "        rot = scs.transform.Rotation.match_vectors(A, B)[0]\n",
    "        transformed2 = rot.apply(transformed)\n",
    "        transformed = transformed2\n",
    "        #print (np.linalg.norm(c.coordinates[[refsite1, refsite2]] - transformed[[ontosite1, ontosite2]] , axis=1))\n",
    "        if max(np.linalg.norm(c.coordinates[[refsite1, refsite2]] - transformed[[ontosite1, ontosite2]] , axis=1)) > 1e-5:\n",
    "            raise ValueError('no rotation')\n",
    "    \n",
    "    if mirrorafter:\n",
    "        a = transformed[ontosite1] - transformed[ontosite2]\n",
    "        for site in range(20):\n",
    "            v = transformed[site].copy()\n",
    "            transformed[site] = v- 2*a*np.dot(v, a) / np.dot(a, a)\n",
    "    if noflip:      \n",
    "        a = transformed[ontosite1] + transformed[ontosite2]\n",
    "        a = a/np.linalg.norm(a)*np.pi\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        transformed = rot.apply(transformed)\n",
    "        #print (np.linalg.norm(c.coordinates[[refsite1, refsite2]] - transformed[[ontosite1, ontosite2]] , axis=1))\n",
    "    \n",
    "    if reflectrotate:\n",
    "        a = transformed[ontosite1] - transformed[ontosite2]\n",
    "        for site in range(20):\n",
    "            v = transformed[site].copy()\n",
    "            transformed[site] = v- 2*a*np.dot(v, a) / np.dot(a, a)\n",
    "        a = a/np.linalg.norm(a)*(np.pi)\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        transformed = rot.apply(transformed)\n",
    "    found = []\n",
    "    for site in range(len(c.coordinates)):\n",
    "        ds = np.linalg.norm(transformed - c.coordinates[site], axis=1)\n",
    "        if min(ds) < 1e-5:\n",
    "            #print (site, np.argmin(ds))\n",
    "            found.append(np.argmin(ds))\n",
    "    #try:\n",
    "    #    print (set(found))#, found[refsite1], ontosite1, found[refsite2], ontosite2)\n",
    "    #except:\n",
    "    #    pass\n",
    "    if set(found) == set([_ for _ in range(len(c.coordinates))]) and found[refsite1] == ontosite1 and found[refsite2] == ontosite2:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('no solution')\n",
    "    return found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=20*20*20*20)\n",
    "def build_reindexing_2_cached(a, b, c, d):\n",
    "    return build_reindexing_2_merged(a, b, c,d)\n",
    "@functools.lru_cache(maxsize=20*20*20*20)\n",
    "def build_reindexing_1_cached(a, b):\n",
    "    return build_reindexing_1_merged(a, b)\n",
    "@functools.lru_cache(200)\n",
    "def read_DENSITY_cached(fn):\n",
    "    return read_DENSITY(fn)\n",
    "@functools.lru_cache(30)\n",
    "def get_grid_ds(j):\n",
    "    return 1/(np.linalg.norm(grid_points - c.coordinates[j], axis=1)*1.8897259885789)\n",
    "@functools.lru_cache(maxsize=20*20)\n",
    "def get_deriv_cached(i, j):\n",
    "    return get_deriv(i, j)\n",
    "changed_site, grid_points, grid_densweight = read_grid_first_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-143-e6b92fe9211f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-143-e6b92fe9211f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    def build_reindexing_2(a, b, c, d):\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# warm caches\n",
    "def test_all_pairs(n):\n",
    "    ds = scs.distance.squareform(scs.distance.pdist(c.coordinates))\n",
    "    dvals = np.unique(np.round(ds, 2))\n",
    "    xs, ys = np.where(abs(ds - dvals[n])< 0.1)\n",
    "    tosites = (0,1, 2, 8, 10, 16)[n]\n",
    "    for i, j in zip(xs, ys):\n",
    "        if i == j:\n",
    "            continue\n",
    "        try:\n",
    "            build_reindexing_2_merged(i, j, 0, tosites)\n",
    "        except:\n",
    "            print (i, j, 0, tosites)\n",
    "for i in range(6):\n",
    "    print (i)\n",
    "    test_all_pairs(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guido/miniconda3/envs/analysis/lib/python3.6/site-packages/ipykernel_launcher.py:52: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 5.57754 s\n",
       "File: <ipython-input-183-cf0e87111acf>\n",
       "Function: get_predictions at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def get_predictions(comb = [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 7]):\n",
       "     2                                               #rho, dsingle, dneigh1, dneigh2, dneigh3, dneigh4, dneigh5 = read_densities()\n",
       "     3                                                   \n",
       "     4         1          4.0      4.0      0.0      E =0 #-758.072029908548 # base energy\n",
       "     5         1         31.0     31.0      0.0      deltaZ = np.array(comb) - 6\n",
       "     6                                                   \n",
       "     7         1         20.0     20.0      0.0      zs = np.array([int(_) for _ in comb])\n",
       "     8         1         18.0     18.0      0.0      zsref = np.zeros(20) + 6\n",
       "     9                                               \n",
       "    10         1        497.0    497.0      0.0      E -= get_nucnuc(zsref)\n",
       "    11         1        419.0    419.0      0.0      E += get_nucnuc(zs)\n",
       "    12                                               \n",
       "    13                                               # 0-th order, no rotation necessary, should be hard zero\n",
       "    14                                               #ds = np.linalg.norm(grid_points - c.coordinates[0], axis=1)\n",
       "    15                                               #es = (rho * grid_weights / ds).sum()\n",
       "    16                                               #for idx, Z in enumerate(comb):\n",
       "    17                                               #    if deltaZ[idx] == 0:\n",
       "    18                                               #        continue\n",
       "    19                                               #    E += np.sum(deltaZ[idx] * rho * grid_weights / ds)\n",
       "    20                                               \n",
       "    21                                               # 1st order\n",
       "    22         1     158967.0 158967.0      2.9      changed_site, grid_points, grid_densweight = read_grid_first_order()\n",
       "    23         1        241.0    241.0      0.0      dV = np.zeros(grid_densweight.shape)\n",
       "    24        21         82.0      3.9      0.0      for idx, Z in enumerate(comb):\n",
       "    25        20        125.0      6.2      0.0          if deltaZ[idx] == 0:\n",
       "    26         8         20.0      2.5      0.0              continue\n",
       "    27        12         97.0      8.1      0.0          mapping = build_reindexing_1_cached(idx, changed_site)\n",
       "    28                                                   \n",
       "    29       252       1121.0      4.4      0.0          for j in range(20): \n",
       "    30       240       1884.0      7.8      0.0              if deltaZ[mapping[j]] == 0:\n",
       "    31        96        366.0      3.8      0.0                  continue\n",
       "    32       144        800.0      5.6      0.0              ds = get_grid_ds(j)\n",
       "    33       144     201349.0   1398.3      3.6              dV += deltaZ[idx] * deltaZ[mapping[j]]* ds\n",
       "    34                                                       #E += np.sum(deltaZ[idx] * deltaZ[mapping[j]] * grid_densweight / ds)/2\n",
       "    35         1       1024.0   1024.0      0.0      E += np.sum(dV * grid_densweight)/2\n",
       "    36                                               \n",
       "    37                                               # 2nd order\n",
       "    38         1        362.0    362.0      0.0      dV *= 0\n",
       "    39        21         76.0      3.6      0.0      for idx_i, Z_i in enumerate(comb):\n",
       "    40        20        119.0      6.0      0.0          if deltaZ[idx_i] == 0:\n",
       "    41         8         21.0      2.6      0.0              continue\n",
       "    42       252       1025.0      4.1      0.0          for idx_j, Z_j in enumerate(comb):\n",
       "    43       240       1266.0      5.3      0.0              if deltaZ[idx_j] == 0:\n",
       "    44        96        247.0      2.6      0.0                  continue\n",
       "    45                                                       \n",
       "    46                                                       # t_i: target for idx_i after rotation\n",
       "    47                                                       # deriv_pair: part of derivative after pair-mapping\n",
       "    48                                                       # deriv_single: part of derivative after single-mapping\n",
       "    49       144        895.0      6.2      0.0              t_i, t_j, deriv_pair, deriv_single = get_deriv_cached(idx_i, idx_j)\n",
       "    50                                                       \n",
       "    51                                                       # pairwise mapping\n",
       "    52       144        472.0      3.3      0.0              if idx_i != idx_j:\n",
       "    53       132        356.0      2.7      0.0                  try:\n",
       "    54       132        873.0      6.6      0.0                      mapping = build_reindexing_2_cached(idx_i, idx_j, t_i, t_j)\n",
       "    55                                                           except:\n",
       "    56                                                               print (idx_i, idx_j, t_i, t_j)\n",
       "    57      2772      12257.0      4.4      0.2                  for j in range(20): \n",
       "    58      2640      17445.0      6.6      0.3                      if deltaZ[mapping[j]] == 0:\n",
       "    59      1056       2959.0      2.8      0.1                          continue\n",
       "    60      1584       9041.0      5.7      0.2                      ds = get_grid_ds(j)\n",
       "    61                                                               #E += np.sum(deltaZ[idx] * deltaZ[mapping[j]] * grid_densweight / ds) / 6\n",
       "    62      1584    2136129.0   1348.6     38.3                      dV += deltaZ[idx] * deltaZ[mapping[j]] * ds\n",
       "    63                                                       \n",
       "    64                                                       # single mapping\n",
       "    65       144     544373.0   3780.4      9.8              mapping = build_reindexing_1(idx_j, 0)\n",
       "    66      3024      13461.0      4.5      0.2              for j in range(20): \n",
       "    67      2880      18143.0      6.3      0.3                  if deltaZ[mapping[j]] == 0:\n",
       "    68      1152       3311.0      2.9      0.1                      continue\n",
       "    69      1728       8918.0      5.2      0.2                  ds = get_grid_ds(j)\n",
       "    70                                                           #E += np.sum(deltaZ[idx] * deltaZ[mapping[j]] * grid_densweight / ds) / 6\n",
       "    71      1728    2437421.0   1410.5     43.7                  dV += deltaZ[idx] * deltaZ[mapping[j]] * ds\n",
       "    72         1       1298.0   1298.0      0.0      E += np.sum(dV * grid_densweight)/6\n",
       "    73                                                       \n",
       "    74         1          3.0      3.0      0.0      return E"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_predictions(comb = [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 7]):\n",
    "    #rho, dsingle, dneigh1, dneigh2, dneigh3, dneigh4, dneigh5 = read_densities()\n",
    "        \n",
    "    E =0 #-758.072029908548 # base energy\n",
    "    deltaZ = np.array(comb) - 6\n",
    "        \n",
    "    zs = np.array([int(_) for _ in comb])\n",
    "    zsref = np.zeros(20) + 6\n",
    "    \n",
    "    E -= get_nucnuc(zsref)\n",
    "    E += get_nucnuc(zs)\n",
    "    \n",
    "    # 0-th order, no rotation necessary, should be hard zero\n",
    "    #ds = np.linalg.norm(grid_points - c.coordinates[0], axis=1)\n",
    "    #es = (rho * grid_weights / ds).sum()\n",
    "    #for idx, Z in enumerate(comb):\n",
    "    #    if deltaZ[idx] == 0:\n",
    "    #        continue\n",
    "    #    E += np.sum(deltaZ[idx] * rho * grid_weights / ds)\n",
    "    \n",
    "    # 1st order\n",
    "    changed_site, grid_points, grid_densweight = read_grid_first_order()\n",
    "    dV = np.zeros(grid_densweight.shape)\n",
    "    for idx, Z in enumerate(comb):\n",
    "        if deltaZ[idx] == 0:\n",
    "            continue\n",
    "        mapping = build_reindexing_1_cached(idx, changed_site)\n",
    "        \n",
    "        for j in range(20): \n",
    "            if deltaZ[mapping[j]] == 0:\n",
    "                continue\n",
    "            ds = get_grid_ds(j)\n",
    "            dV += deltaZ[idx] * deltaZ[mapping[j]]* ds\n",
    "            #E += np.sum(deltaZ[idx] * deltaZ[mapping[j]] * grid_densweight / ds)/2\n",
    "    E += np.sum(dV * grid_densweight)/2\n",
    "    \n",
    "    # 2nd order\n",
    "    dV *= 0\n",
    "    for idx_i, Z_i in enumerate(comb):\n",
    "        if deltaZ[idx_i] == 0:\n",
    "            continue\n",
    "        for idx_j, Z_j in enumerate(comb):\n",
    "            if deltaZ[idx_j] == 0:\n",
    "                continue\n",
    "            \n",
    "            # t_i: target for idx_i after rotation\n",
    "            # deriv_pair: part of derivative after pair-mapping\n",
    "            # deriv_single: part of derivative after single-mapping\n",
    "            t_i, t_j, deriv_pair, deriv_single = get_deriv_cached(idx_i, idx_j)\n",
    "            \n",
    "            # pairwise mapping\n",
    "            if idx_i != idx_j:\n",
    "                try:\n",
    "                    mapping = build_reindexing_2_cached(idx_i, idx_j, t_i, t_j)\n",
    "                except:\n",
    "                    print (idx_i, idx_j, t_i, t_j)\n",
    "                for j in range(20): \n",
    "                    if deltaZ[mapping[j]] == 0:\n",
    "                        continue\n",
    "                    ds = get_grid_ds(j)\n",
    "                    #E += np.sum(deltaZ[idx] * deltaZ[mapping[j]] * grid_densweight / ds) / 6\n",
    "                    dV += deltaZ[idx] * deltaZ[mapping[j]] * ds\n",
    "            \n",
    "            # single mapping\n",
    "            mapping = build_reindexing_1(idx_j, 0)\n",
    "            for j in range(20): \n",
    "                if deltaZ[mapping[j]] == 0:\n",
    "                    continue\n",
    "                ds = get_grid_ds(j)\n",
    "                #E += np.sum(deltaZ[idx] * deltaZ[mapping[j]] * grid_densweight / ds) / 6\n",
    "                dV += deltaZ[idx] * deltaZ[mapping[j]] * ds\n",
    "    E += np.sum(dV * grid_densweight)/6\n",
    "            \n",
    "    return E\n",
    "%lprun -f get_predictions get_predictions([int(_) for _ in '57766576666555776675'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guido/miniconda3/envs/analysis/lib/python3.6/site-packages/ipykernel_launcher.py:52: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(552844,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 6.16006 s\n",
       "File: <ipython-input-157-b8d355666068>\n",
       "Function: get_deriv at line 55\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    55                                           def get_deriv(i, j):\n",
       "    56                                               \"\"\" Returns \n",
       "    57                                               t_i : atom index of i after rotation\n",
       "    58                                               t_j : atom index of j after rotation\n",
       "    59                                               deriv_pair : the density to be integrated after pairwise rotation\n",
       "    60                                               deriv_single : density to be integrated after single rotation \"\"\"\n",
       "    61                                               \n",
       "    62       144      10665.0     74.1      0.2      d = np.linalg.norm(c.coordinates[i] - c.coordinates[j])\n",
       "    63       144      39788.0    276.3      0.6      geo = np.argmin(np.abs(np.array(sorted(set(np.round(scs.distance.pdist(c.coordinates), 2)))) - d))\n",
       "    64       144        556.0      3.9      0.0      sites = (0, (1, 2, 8, 10, 16)[geo])\n",
       "    65       144        397.0      2.8      0.0      i, j = sites\n",
       "    66       144        378.0      2.6      0.0      delta = 0.05\n",
       "    67                                               \n",
       "    68       144        392.0      2.7      0.0      assert i == 0\n",
       "    69       144        943.0      6.5      0.0      midgrid, midweight, middens = read_DENSITY_cached('c20-data/derivatives/order-0/site-all-cc/DENSITY')\n",
       "    70                                               # prefill output\n",
       "    71       144      38070.0    264.4      0.6      deriv_single = np.zeros(middens.shape)\n",
       "    72       144      42431.0    294.7      0.7      deriv_pair = np.zeros(middens.shape)\n",
       "    73                                               \n",
       "    74       144       1289.0      9.0      0.0      iupgrid, iupweight, iupdens = read_DENSITY_cached('c20-data/derivatives/order-1/site-0-up/DENSITY')\n",
       "    75       144        735.0      5.1      0.0      idngrid, idnweight, idndens = read_DENSITY_cached('c20-data/derivatives/order-1/site-0-dn/DENSITY')\n",
       "    76                                               \n",
       "    77       144        499.0      3.5      0.0      if i == j:\n",
       "    78                                                   deriv_single = (iupdens + idndens - 2 * middens)/(delta**2)\n",
       "    79                                               else:\n",
       "    80       144        402.0      2.8      0.0          rhojup = iupdens\n",
       "    81       144        383.0      2.7      0.0          rhojdn = idndens\n",
       "    82       144       1323.0      9.2      0.0          upgrid, upweight, updens = read_DENSITY_cached('c20-data/derivatives/order-2/site-0-%d-up/DENSITY' % j)\n",
       "    83       144        612.0      4.2      0.0          dngrid, dnweight, dndens = read_DENSITY_cached('c20-data/derivatives/order-2/site-0-%d-dn/DENSITY' % j)\n",
       "    84                                                   \n",
       "    85       144    4246276.0  29488.0     68.9          deriv_pair = (updens + dndens + 2 * middens - iupdens - idndens) / (2 * delta**2)\n",
       "    86       144    1774093.0  12320.1     28.8          deriv_single = (- rhojup - rhojdn) / (2 * delta**2)\n",
       "    87                                               \n",
       "    88       144        833.0      5.8      0.0      return i, j, deriv_pair, deriv_single"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f get_deriv get_predictions([int(_) for _ in '57766576666555776675'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis]",
   "language": "python",
   "name": "conda-env-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
