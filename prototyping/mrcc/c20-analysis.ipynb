{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read list of nuclear charges, give energy predictions up to nth order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import qml\n",
    "import scipy.spatial as scs\n",
    "import scipy.interpolate as sci\n",
    "import functools\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = qml.Compound('../../test/c20.xyz')\n",
    "def _get_nn(refsite):\n",
    "    distances = np.linalg.norm(c.coordinates - c.coordinates[refsite], axis=1)\n",
    "    return np.argsort(distances)[1:4]\n",
    "def build_reindexing_1_merged(refsite, ontosite):\n",
    "    cog = np.mean(c.coordinates, axis=0)\n",
    "    valid = False\n",
    "    for Ann in _get_nn(refsite):\n",
    "        for Bnn in _get_nn(ontosite):\n",
    "            A = c.coordinates[[refsite, Ann]]\n",
    "            B = c.coordinates[[ontosite, Bnn]]\n",
    "            rot = scs.transform.Rotation.match_vectors(A, B)[0]\n",
    "            transformed = rot.apply(c.coordinates)\n",
    "            found = []\n",
    "            for site in range(len(c.coordinates)):\n",
    "                ds = np.linalg.norm(transformed - c.coordinates[site], axis=1)\n",
    "                if min(ds) < 1e-5:\n",
    "                    found.append(np.argmin(ds))\n",
    "            if set(found) == set([_ for _ in range(len(c.coordinates))]) and found[refsite] == ontosite:\n",
    "                valid = True\n",
    "                break\n",
    "        if valid:\n",
    "            break\n",
    "    if not valid:\n",
    "        raise ValueError('no solution')\n",
    "    return found\n",
    "\n",
    "def read_DENSITY(fn):\n",
    "    with open(fn, 'r') as fh:\n",
    "        _ = np.fromfile(fh, 'i4')\n",
    "        q = _[3:-1].view(np.float64)\n",
    "        ccdensity = q.reshape((-1, 10))\n",
    "    ccdensity = ccdensity[:, 1:6]\n",
    "    return ccdensity[:, :3], ccdensity[:, 3], ccdensity[:, 4]\n",
    "\n",
    "def read_grid_first_order():\n",
    "    changed_site = 0\n",
    "    delta = 0.1\n",
    "    \n",
    "    upgrid, upweight, updens = read_DENSITY_cached('c20-data/derivatives/order-1/site-0-up/DENSITY')\n",
    "    dngrid, dnweight, dndens = read_DENSITY_cached('c20-data/derivatives/order-1/site-0-dn/DENSITY')\n",
    "    \n",
    "    if not np.allclose(upgrid, dngrid):\n",
    "        raise ValueError('Grid?')\n",
    "        \n",
    "    if not np.allclose(upweight, dnweight):\n",
    "        raise ValueError('Grid?')\n",
    "    \n",
    "    return changed_site, upgrid, ((updens - dndens) / delta)*upweight\n",
    "def get_nucnuc(zs):\n",
    "    ds = scs.distance.squareform(scs.distance.pdist(c.coordinates))*1.8897259885789\n",
    "    q = np.outer(zs, zs)/ds\n",
    "    np.fill_diagonal(q, 0)\n",
    "    return q.sum()/2    \n",
    "def get_deriv(i, j):\n",
    "    \"\"\" Returns \n",
    "    t_i : atom index of i after rotation\n",
    "    t_j : atom index of j after rotation\n",
    "    deriv_pair : the density to be integrated after pairwise rotation\n",
    "    deriv_single : density to be integrated after single rotation \"\"\"\n",
    "    \n",
    "    d = np.linalg.norm(c.coordinates[i] - c.coordinates[j])\n",
    "    geo = np.argmin(np.abs(np.array(sorted(set(np.round(scs.distance.pdist(c.coordinates), 2)))) - d))\n",
    "    sites = (0, (1, 2, 8, 10, 16)[geo])\n",
    "    i, j = sites\n",
    "    delta = 0.1\n",
    "    \n",
    "    assert i == 0\n",
    "    midgrid, midweight, middens = read_DENSITY_cached('c20-data/derivatives/order-0/site-all-cc/DENSITY')\n",
    "    # prefill output\n",
    "    deriv_single = np.zeros(middens.shape)\n",
    "    deriv_pair = np.zeros(middens.shape)\n",
    "    \n",
    "    iupgrid, iupweight, iupdens = read_DENSITY_cached('c20-data/derivatives/order-1/site-0-up/DENSITY')\n",
    "    idngrid, idnweight, idndens = read_DENSITY_cached('c20-data/derivatives/order-1/site-0-dn/DENSITY')\n",
    "    if i == j:\n",
    "        deriv_single = (iupdens + idndens - 2 * middens)/(delta**2)\n",
    "    else:\n",
    "        rhojup = iupdens\n",
    "        rhojdn = idndens\n",
    "        upgrid, upweight, updens = read_DENSITY_cached('c20-data/derivatives/order-2/site-0-%d-up/DENSITY' % j)\n",
    "        dngrid, dnweight, dndens = read_DENSITY_cached('c20-data/derivatives/order-2/site-0-%d-dn/DENSITY' % j)\n",
    "        \n",
    "        deriv_pair = (updens + dndens + 2 * middens - iupdens - idndens) / (2 * delta**2)\n",
    "        deriv_single = (- rhojup - rhojdn) / (2 * delta**2)\n",
    "    \n",
    "    return i, j, deriv_pair * midweight, deriv_single * midweight\n",
    "def build_reindexing_2_merged(refsite1, refsite2, ontosite1, ontosite2):\n",
    "    if refsite1 == ontosite1 and refsite2 == ontosite2:\n",
    "        return list(range(20))\n",
    "    for inverse in (True, False):\n",
    "        for asc in (True, False):\n",
    "            for mirror in (True, False):\n",
    "                for mirrorafter in (True, False):\n",
    "                    for noflip in (True, False):\n",
    "                        for rotate60 in (True, False):\n",
    "                            for rotate90 in (True, False):\n",
    "                                for reflectrotate in (True, False):\n",
    "                                    for rotate120 in (True, False):\n",
    "                                        try:\n",
    "                                            return do_it(refsite1, refsite2, ontosite1, ontosite2, inverse, asc, mirror, mirrorafter, noflip, rotate60, rotate90, reflectrotate, rotate120)\n",
    "                                        except ValueError:\n",
    "                                            continue\n",
    "    raise ValueError('No luck.')\n",
    "def do_it(refsite1, refsite2, ontosite1, ontosite2, inverse, asc, mirror, mirrorafter, noflip, rotate60, rotate90, reflectrotate,rotate120):\n",
    "    #print (inverse, asc, mirror, mirrorafter, noflip,rotate60, rotate90)\n",
    "    valid = False\n",
    "    if inverse:\n",
    "        coordinates = np.copy(c.coordinates)*(-1)\n",
    "    else:\n",
    "        coordinates = np.copy(c.coordinates)\n",
    "    \n",
    "    A = c.coordinates[[refsite1, refsite2]]\n",
    "    B = coordinates[[ontosite1, ontosite2]]\n",
    "    \n",
    "    if rotate60:\n",
    "        a = B[0] -B[1]\n",
    "        a = a/np.linalg.norm(a)*(np.pi/3)\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        coordinates = rot.apply(coordinates)\n",
    "    if rotate90:\n",
    "        a = B[0] -B[1]\n",
    "        a = a/np.linalg.norm(a)*(np.pi/4)\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        coordinates = rot.apply(coordinates)\n",
    "    if rotate120:\n",
    "        a = B[0] -B[1]\n",
    "        a = a/np.linalg.norm(a)*(2*np.pi/3)\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        coordinates = rot.apply(coordinates)\n",
    "    if mirror:\n",
    "        ax1 = A.sum(axis=0)\n",
    "        ax2 = B.sum(axis=0)\n",
    "        a = ax1 - ax2\n",
    "        for site in range(20):\n",
    "            v = coordinates[site].copy()\n",
    "            coordinates[site] = v- 2*a*np.dot(v, a) / np.dot(a, a)\n",
    "        transformed = coordinates\n",
    "    else:\n",
    "        A = c.coordinates[[refsite1, refsite2]]\n",
    "        B = coordinates[[ontosite1, ontosite2]]\n",
    "        #print (np.linalg.norm(c.coordinates[[refsite1, refsite2]] - coordinates[[ontosite1, ontosite2]] , axis=1))\n",
    "        if asc:\n",
    "            index = 0\n",
    "        else:\n",
    "            index = 1\n",
    "\n",
    "        # rotate first\n",
    "        a = np.cross(A[index], (0,0,1))\n",
    "        b = np.cross(B[index], (0, 0, 1))\n",
    "        rot = scs.transform.Rotation.match_vectors([A[index], a], [B[index], b])[0]\n",
    "        transformed = rot.apply(c.coordinates)\n",
    "        #print (np.linalg.norm(c.coordinates[[refsite1, refsite2]] - transformed[[ontosite1, ontosite2]] , axis=1))\n",
    "\n",
    "        # rotate second\n",
    "        A = c.coordinates[[refsite1, refsite2]]\n",
    "        B = transformed[[ontosite1, ontosite2]]\n",
    "        rot = scs.transform.Rotation.match_vectors(A, B)[0]\n",
    "        transformed2 = rot.apply(transformed)\n",
    "        transformed = transformed2\n",
    "        #print (np.linalg.norm(c.coordinates[[refsite1, refsite2]] - transformed[[ontosite1, ontosite2]] , axis=1))\n",
    "        if max(np.linalg.norm(c.coordinates[[refsite1, refsite2]] - transformed[[ontosite1, ontosite2]] , axis=1)) > 1e-5:\n",
    "            raise ValueError('no rotation')\n",
    "    \n",
    "    if mirrorafter:\n",
    "        a = transformed[ontosite1] - transformed[ontosite2]\n",
    "        for site in range(20):\n",
    "            v = transformed[site].copy()\n",
    "            transformed[site] = v- 2*a*np.dot(v, a) / np.dot(a, a)\n",
    "    if noflip:      \n",
    "        a = transformed[ontosite1] + transformed[ontosite2]\n",
    "        a = a/np.linalg.norm(a)*np.pi\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        transformed = rot.apply(transformed)\n",
    "        #print (np.linalg.norm(c.coordinates[[refsite1, refsite2]] - transformed[[ontosite1, ontosite2]] , axis=1))\n",
    "    \n",
    "    if reflectrotate:\n",
    "        a = transformed[ontosite1] - transformed[ontosite2]\n",
    "        for site in range(20):\n",
    "            v = transformed[site].copy()\n",
    "            transformed[site] = v- 2*a*np.dot(v, a) / np.dot(a, a)\n",
    "        a = a/np.linalg.norm(a)*(np.pi)\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        transformed = rot.apply(transformed)\n",
    "    found = []\n",
    "    for site in range(len(c.coordinates)):\n",
    "        ds = np.linalg.norm(transformed - c.coordinates[site], axis=1)\n",
    "        if min(ds) < 1e-5:\n",
    "            #print (site, np.argmin(ds))\n",
    "            found.append(np.argmin(ds))\n",
    "    #try:\n",
    "    #    print (set(found))#, found[refsite1], ontosite1, found[refsite2], ontosite2)\n",
    "    #except:\n",
    "    #    pass\n",
    "    if set(found) == set([_ for _ in range(len(c.coordinates))]) and found[refsite1] == ontosite1 and found[refsite2] == ontosite2:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('no solution')\n",
    "    return found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=20*20*20*20)\n",
    "def build_reindexing_2_cached(a, b, c, d):\n",
    "    return build_reindexing_2_merged(a, b, c,d)\n",
    "@functools.lru_cache(maxsize=20*20*20*20)\n",
    "def build_reindexing_1_cached(a, b):\n",
    "    return build_reindexing_1_merged(a, b)\n",
    "@functools.lru_cache(200)\n",
    "def read_DENSITY_cached(fn):\n",
    "    return read_DENSITY(fn)\n",
    "@functools.lru_cache(30)\n",
    "def get_grid_ds(j):\n",
    "    return 1/(np.linalg.norm(grid_points - c.coordinates[j], axis=1)*1.8897259885789)\n",
    "@functools.lru_cache(maxsize=20*20)\n",
    "def get_deriv_cached(i, j):\n",
    "    return get_deriv(i, j)\n",
    "changed_site, grid_points, grid_densweight = read_grid_first_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# warm caches\n",
    "def test_all_pairs(n):\n",
    "    ds = scs.distance.squareform(scs.distance.pdist(c.coordinates))\n",
    "    dvals = np.unique(np.round(ds, 2))\n",
    "    xs, ys = np.where(abs(ds - dvals[n])< 0.1)\n",
    "    tosites = (0,1, 2, 8, 10, 16)[n]\n",
    "    for i, j in zip(xs, ys):\n",
    "        if i == j:\n",
    "            continue\n",
    "        try:\n",
    "            build_reindexing_2_merged(i, j, 0, tosites)\n",
    "        except:\n",
    "            print (i, j, 0, tosites)\n",
    "for i in range(6):\n",
    "    print (i)\n",
    "    test_all_pairs(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guido/miniconda3/envs/analysis/lib/python3.6/site-packages/ipykernel_launcher.py:52: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "def get_predictions(comb = [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 7]):\n",
    "    #rho, dsingle, dneigh1, dneigh2, dneigh3, dneigh4, dneigh5 = read_densities()\n",
    "        \n",
    "    E =0 #-758.072029908548 # base energy\n",
    "    deltaZ = np.array(comb) - 6\n",
    "        \n",
    "    zs = np.array([int(_) for _ in comb])\n",
    "    zsref = np.zeros(20) + 6\n",
    "    \n",
    "    E -= get_nucnuc(zsref)\n",
    "    E += get_nucnuc(zs)\n",
    "    \n",
    "    # 0-th order, no rotation necessary, should be hard zero\n",
    "    #ds = np.linalg.norm(grid_points - c.coordinates[0], axis=1)\n",
    "    #es = (rho * grid_weights / ds).sum()\n",
    "    #for idx, Z in enumerate(comb):\n",
    "    #    if deltaZ[idx] == 0:\n",
    "    #        continue\n",
    "    #    E += np.sum(deltaZ[idx] * rho * grid_weights / ds)\n",
    "    \n",
    "    # 1st order\n",
    "    changed_site, grid_points, grid_densweight = read_grid_first_order()\n",
    "    dV = np.zeros(grid_densweight.shape)\n",
    "    for idx, Z in enumerate(comb):\n",
    "        if deltaZ[idx] == 0:\n",
    "            continue\n",
    "        mapping = build_reindexing_1_cached(idx, changed_site)\n",
    "        \n",
    "        for j in range(20): \n",
    "            if deltaZ[mapping[j]] == 0:\n",
    "                continue\n",
    "            ds = get_grid_ds(j)\n",
    "            dV += deltaZ[idx] * deltaZ[mapping[j]]* ds\n",
    "            #E += np.sum(deltaZ[idx] * deltaZ[mapping[j]] * grid_densweight / ds)/2\n",
    "    E += np.sum(dV * grid_densweight)/2\n",
    "    \n",
    "    # 2nd order\n",
    "    del dV, idx\n",
    "    dE = np.zeros(grid_densweight.shape)\n",
    "    for idx_i, Z_i in enumerate(comb):\n",
    "        if deltaZ[idx_i] == 0:\n",
    "            continue\n",
    "        for idx_j, Z_j in enumerate(comb):\n",
    "            if deltaZ[idx_j] == 0:\n",
    "                continue\n",
    "            \n",
    "            # t_i: target for idx_i after rotation\n",
    "            # deriv_pair: part of derivative after pair-mapping\n",
    "            # deriv_single: part of derivative after single-mapping\n",
    "            t_i, t_j, deriv_pair, deriv_single = get_deriv_cached(idx_i, idx_j)\n",
    "            \n",
    "            # pairwise mapping\n",
    "            if idx_i != idx_j:\n",
    "                try:\n",
    "                    mapping = build_reindexing_2_cached(idx_i, idx_j, t_i, t_j)\n",
    "                except:\n",
    "                    print (idx_i, idx_j, t_i, t_j)\n",
    "                for j in range(20): \n",
    "                    if deltaZ[mapping[j]] == 0:\n",
    "                        continue\n",
    "                    ds = get_grid_ds(j)\n",
    "                    dE += deltaZ[idx_i] *deltaZ[idx_j] * deltaZ[mapping[j]] * ds * deriv_pair\n",
    "            \n",
    "            # single mapping\n",
    "            mapping = build_reindexing_1(idx_j, 0)\n",
    "            for j in range(20): \n",
    "                if deltaZ[mapping[j]] == 0:\n",
    "                    continue\n",
    "                ds = get_grid_ds(j)\n",
    "                dE += deltaZ[idx_i] * deltaZ[idx_j] * deltaZ[mapping[j]] * ds * deriv_single\n",
    "    E += np.sum(dE)/6\n",
    "            \n",
    "    return -E\n",
    "%lprun -f get_predictions print (get_predictions([int(_) for _ in '57766576666555776675']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.908634707589954e-07\n",
      "-1157.6925133820623\n"
     ]
    }
   ],
   "source": [
    "t_i, t_j, deriv_pair, deriv_single = get_deriv(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.77058213579852"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(deriv_single*grid_densweight).sum()+(grid_densweight*deriv_pair).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1325303460.9896092"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis]",
   "language": "python",
   "name": "conda-env-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
