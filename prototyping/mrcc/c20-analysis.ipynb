{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read list of nuclear charges, give energy predictions up to nth order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import qml\n",
    "import scipy.spatial as scs\n",
    "import scipy.interpolate as sci\n",
    "import functools\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = qml.Compound('../../test/c20.xyz')\n",
    "def _get_nn(refsite):\n",
    "    distances = np.linalg.norm(c.coordinates - c.coordinates[refsite], axis=1)\n",
    "    return np.argsort(distances)[1:4]\n",
    "def build_reindexing_1_merged(refsite, ontosite):\n",
    "    cog = np.mean(c.coordinates, axis=0)\n",
    "    valid = False\n",
    "    for Ann in _get_nn(refsite):\n",
    "        for Bnn in _get_nn(ontosite):\n",
    "            A = c.coordinates[[refsite, Ann]]\n",
    "            B = c.coordinates[[ontosite, Bnn]]\n",
    "            rot = scs.transform.Rotation.match_vectors(A, B)[0]\n",
    "            transformed = rot.apply(c.coordinates)\n",
    "            found = []\n",
    "            for site in range(len(c.coordinates)):\n",
    "                ds = np.linalg.norm(transformed - c.coordinates[site], axis=1)\n",
    "                if min(ds) < 1e-5:\n",
    "                    found.append(np.argmin(ds))\n",
    "            if set(found) == set([_ for _ in range(len(c.coordinates))]) and found[refsite] == ontosite:\n",
    "                valid = True\n",
    "                break\n",
    "        if valid:\n",
    "            break\n",
    "    if not valid:\n",
    "        raise ValueError('no solution')\n",
    "    return found\n",
    "\n",
    "def read_DENSITY(fn):\n",
    "    with open(fn, 'r') as fh:\n",
    "        _ = np.fromfile(fh, 'i4')\n",
    "        q = _[3:-1].view(np.float64)\n",
    "        ccdensity = q.reshape((-1, 10))\n",
    "    ccdensity = ccdensity[:, 1:6]\n",
    "    return ccdensity[:, :3]/1.8897259885789, ccdensity[:, 3], ccdensity[:, 4]\n",
    "\n",
    "def read_grid_first_order():\n",
    "    changed_site = 0\n",
    "    delta = 0.1\n",
    "    \n",
    "    upgrid, upweight, updens = read_DENSITY_cached('c20-data/derivatives/order-1/site-0-up/DENSITY')\n",
    "    dngrid, dnweight, dndens = read_DENSITY_cached('c20-data/derivatives/order-1/site-0-dn/DENSITY')\n",
    "    \n",
    "    if not np.allclose(upgrid, dngrid):\n",
    "        raise ValueError('Grid?')\n",
    "        \n",
    "    if not np.allclose(upweight, dnweight):\n",
    "        raise ValueError('Grid?')\n",
    "    \n",
    "    return changed_site, upgrid, ((updens - dndens) / delta)*upweight\n",
    "def get_nucnuc(zs):\n",
    "    ds = scs.distance.squareform(scs.distance.pdist(c.coordinates))*1.8897259885789\n",
    "    q = np.outer(zs, zs)/ds\n",
    "    np.fill_diagonal(q, 0)\n",
    "    return q.sum()/2    \n",
    "def get_deriv(i, j):\n",
    "    \"\"\" Returns \n",
    "    t_i : atom index of i after rotation\n",
    "    t_j : atom index of j after rotation\n",
    "    deriv_pair : the density to be integrated after pairwise rotation\n",
    "    deriv_single : density to be integrated after single rotation \"\"\"\n",
    "    \n",
    "    d = np.linalg.norm(c.coordinates[i] - c.coordinates[j])\n",
    "    geo = np.argmin(np.abs(np.array(sorted(set(np.round(scs.distance.pdist(c.coordinates), 2)))) - d))\n",
    "    sites = (0, (1, 2, 8, 10, 16)[geo])\n",
    "    i, j = sites\n",
    "    delta = 0.1\n",
    "    \n",
    "    assert i == 0\n",
    "    midgrid, midweight, middens = read_DENSITY_cached('c20-data/derivatives/order-0/site-all-cc/DENSITY')\n",
    "    # prefill output\n",
    "    deriv_single = np.zeros(middens.shape)\n",
    "    deriv_pair = np.zeros(middens.shape)\n",
    "    \n",
    "    iupgrid, iupweight, iupdens = read_DENSITY_cached('c20-data/derivatives/order-1/site-0-up/DENSITY')\n",
    "    idngrid, idnweight, idndens = read_DENSITY_cached('c20-data/derivatives/order-1/site-0-dn/DENSITY')\n",
    "    if i == j:\n",
    "        deriv_single = (iupdens + idndens - 2 * middens)/(delta**2)\n",
    "    else:\n",
    "        rhojup = iupdens\n",
    "        rhojdn = idndens\n",
    "        upgrid, upweight, updens = read_DENSITY_cached('c20-data/derivatives/order-2/site-0-%d-up/DENSITY' % j)\n",
    "        dngrid, dnweight, dndens = read_DENSITY_cached('c20-data/derivatives/order-2/site-0-%d-dn/DENSITY' % j)\n",
    "        \n",
    "        deriv_pair = (updens + dndens + 2 * middens - iupdens - idndens) / (2 * delta**2)\n",
    "        deriv_single = (- rhojup - rhojdn) / (2 * delta**2)\n",
    "    \n",
    "    return i, j, deriv_pair * midweight, deriv_single * midweight\n",
    "def build_reindexing_2_merged(refsite1, refsite2, ontosite1, ontosite2):\n",
    "    if refsite1 == ontosite1 and refsite2 == ontosite2:\n",
    "        return list(range(20))\n",
    "    for inverse in (True, False):\n",
    "        for asc in (True, False):\n",
    "            for mirror in (True, False):\n",
    "                for mirrorafter in (True, False):\n",
    "                    for noflip in (True, False):\n",
    "                        for rotate60 in (True, False):\n",
    "                            for rotate90 in (True, False):\n",
    "                                for reflectrotate in (True, False):\n",
    "                                    for rotate120 in (True, False):\n",
    "                                        try:\n",
    "                                            return do_it(refsite1, refsite2, ontosite1, ontosite2, inverse, asc, mirror, mirrorafter, noflip, rotate60, rotate90, reflectrotate, rotate120)\n",
    "                                        except ValueError:\n",
    "                                            continue\n",
    "    raise ValueError('No luck.')\n",
    "def do_it(refsite1, refsite2, ontosite1, ontosite2, inverse, asc, mirror, mirrorafter, noflip, rotate60, rotate90, reflectrotate,rotate120):\n",
    "    #print (inverse, asc, mirror, mirrorafter, noflip,rotate60, rotate90)\n",
    "    valid = False\n",
    "    if inverse:\n",
    "        coordinates = np.copy(c.coordinates)*(-1)\n",
    "    else:\n",
    "        coordinates = np.copy(c.coordinates)\n",
    "    \n",
    "    A = c.coordinates[[refsite1, refsite2]]\n",
    "    B = coordinates[[ontosite1, ontosite2]]\n",
    "    \n",
    "    if rotate60:\n",
    "        a = B[0] -B[1]\n",
    "        a = a/np.linalg.norm(a)*(np.pi/3)\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        coordinates = rot.apply(coordinates)\n",
    "    if rotate90:\n",
    "        a = B[0] -B[1]\n",
    "        a = a/np.linalg.norm(a)*(np.pi/4)\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        coordinates = rot.apply(coordinates)\n",
    "    if rotate120:\n",
    "        a = B[0] -B[1]\n",
    "        a = a/np.linalg.norm(a)*(2*np.pi/3)\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        coordinates = rot.apply(coordinates)\n",
    "    if mirror:\n",
    "        ax1 = A.sum(axis=0)\n",
    "        ax2 = B.sum(axis=0)\n",
    "        a = ax1 - ax2\n",
    "        for site in range(20):\n",
    "            v = coordinates[site].copy()\n",
    "            coordinates[site] = v- 2*a*np.dot(v, a) / np.dot(a, a)\n",
    "        transformed = coordinates\n",
    "    else:\n",
    "        A = c.coordinates[[refsite1, refsite2]]\n",
    "        B = coordinates[[ontosite1, ontosite2]]\n",
    "        #print (np.linalg.norm(c.coordinates[[refsite1, refsite2]] - coordinates[[ontosite1, ontosite2]] , axis=1))\n",
    "        if asc:\n",
    "            index = 0\n",
    "        else:\n",
    "            index = 1\n",
    "\n",
    "        # rotate first\n",
    "        a = np.cross(A[index], (0,0,1))\n",
    "        b = np.cross(B[index], (0, 0, 1))\n",
    "        rot = scs.transform.Rotation.match_vectors([A[index], a], [B[index], b])[0]\n",
    "        transformed = rot.apply(c.coordinates)\n",
    "        #print (np.linalg.norm(c.coordinates[[refsite1, refsite2]] - transformed[[ontosite1, ontosite2]] , axis=1))\n",
    "\n",
    "        # rotate second\n",
    "        A = c.coordinates[[refsite1, refsite2]]\n",
    "        B = transformed[[ontosite1, ontosite2]]\n",
    "        rot = scs.transform.Rotation.match_vectors(A, B)[0]\n",
    "        transformed2 = rot.apply(transformed)\n",
    "        transformed = transformed2\n",
    "        #print (np.linalg.norm(c.coordinates[[refsite1, refsite2]] - transformed[[ontosite1, ontosite2]] , axis=1))\n",
    "        if max(np.linalg.norm(c.coordinates[[refsite1, refsite2]] - transformed[[ontosite1, ontosite2]] , axis=1)) > 1e-5:\n",
    "            raise ValueError('no rotation')\n",
    "    \n",
    "    if mirrorafter:\n",
    "        a = transformed[ontosite1] - transformed[ontosite2]\n",
    "        for site in range(20):\n",
    "            v = transformed[site].copy()\n",
    "            transformed[site] = v- 2*a*np.dot(v, a) / np.dot(a, a)\n",
    "    if noflip:      \n",
    "        a = transformed[ontosite1] + transformed[ontosite2]\n",
    "        a = a/np.linalg.norm(a)*np.pi\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        transformed = rot.apply(transformed)\n",
    "        #print (np.linalg.norm(c.coordinates[[refsite1, refsite2]] - transformed[[ontosite1, ontosite2]] , axis=1))\n",
    "    \n",
    "    if reflectrotate:\n",
    "        a = transformed[ontosite1] - transformed[ontosite2]\n",
    "        for site in range(20):\n",
    "            v = transformed[site].copy()\n",
    "            transformed[site] = v- 2*a*np.dot(v, a) / np.dot(a, a)\n",
    "        a = a/np.linalg.norm(a)*(np.pi)\n",
    "        rot = scs.transform.Rotation.from_rotvec(a)\n",
    "        transformed = rot.apply(transformed)\n",
    "    found = []\n",
    "    for site in range(len(c.coordinates)):\n",
    "        ds = np.linalg.norm(transformed - c.coordinates[site], axis=1)\n",
    "        if min(ds) < 1e-5:\n",
    "            #print (site, np.argmin(ds))\n",
    "            found.append(np.argmin(ds))\n",
    "    #try:\n",
    "    #    print (set(found))#, found[refsite1], ontosite1, found[refsite2], ontosite2)\n",
    "    #except:\n",
    "    #    pass\n",
    "    if set(found) == set([_ for _ in range(len(c.coordinates))]) and found[refsite1] == ontosite1 and found[refsite2] == ontosite2:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('no solution')\n",
    "    return found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=20*20*20*20)\n",
    "def build_reindexing_2_cached(a, b, c, d):\n",
    "    return build_reindexing_2_merged(a, b, c,d)\n",
    "@functools.lru_cache(maxsize=20*20*20*20)\n",
    "def build_reindexing_1_cached(a, b):\n",
    "    return build_reindexing_1_merged(a, b)\n",
    "@functools.lru_cache(200)\n",
    "def read_DENSITY_cached(fn):\n",
    "    return read_DENSITY(fn)\n",
    "@functools.lru_cache(30)\n",
    "def get_grid_ds(j):\n",
    "    return 1/(np.linalg.norm(grid_points - c.coordinates[j], axis=1)*1.8897259885789)\n",
    "@functools.lru_cache(maxsize=20*20)\n",
    "def get_deriv_cached(i, j):\n",
    "    return get_deriv(i, j)\n",
    "changed_site, grid_points, grid_densweight = read_grid_first_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# warm caches\n",
    "def test_all_pairs(n):\n",
    "    ds = scs.distance.squareform(scs.distance.pdist(c.coordinates))\n",
    "    dvals = np.unique(np.round(ds, 2))\n",
    "    xs, ys = np.where(abs(ds - dvals[n])< 0.1)\n",
    "    tosites = (0,1, 2, 8, 10, 16)[n]\n",
    "    for i, j in zip(xs, ys):\n",
    "        if i == j:\n",
    "            continue\n",
    "        try:\n",
    "            build_reindexing_2_merged(i, j, 0, tosites)\n",
    "        except:\n",
    "            print (i, j, 0, tosites)\n",
    "for i in range(6):\n",
    "    print (i)\n",
    "    test_all_pairs(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guido/miniconda3/envs/analysis/lib/python3.6/site-packages/ipykernel_launcher.py:52: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn -1.3720936347899624\n",
      "f -0.15746451062763975\n",
      "s -12.903983175907072\n",
      "-14.433541321324675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 36.2176 s\n",
       "File: <ipython-input-6-44cb0045b22b>\n",
       "Function: get_predictions at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def get_predictions(comb):\n",
       "     2                                               #rho, dsingle, dneigh1, dneigh2, dneigh3, dneigh4, dneigh5 = read_densities()\n",
       "     3                                                   \n",
       "     4         1          5.0      5.0      0.0      E =0#-758.072029908548 # base energy\n",
       "     5         1         52.0     52.0      0.0      deltaZ = np.array(comb) - 6\n",
       "     6                                                   \n",
       "     7         1         19.0     19.0      0.0      zs = np.array([int(_) for _ in comb])\n",
       "     8         1         21.0     21.0      0.0      zsref = np.zeros(20) + 6\n",
       "     9                                               \n",
       "    10         1        584.0    584.0      0.0      E -= get_nucnuc(zsref)\n",
       "    11         1        216.0    216.0      0.0      E += get_nucnuc(zs)\n",
       "    12         1        143.0    143.0      0.0      print ('nn', E)\n",
       "    13                                               \n",
       "    14                                               # 0-th order, no rotation necessary, should be hard zero\n",
       "    15                                               #ds = np.linalg.norm(grid_points - c.coordinates[0], axis=1)\n",
       "    16                                               #es = (rho * grid_weights / ds).sum()\n",
       "    17                                               #for idx, Z in enumerate(comb):\n",
       "    18                                               #    if deltaZ[idx] == 0:\n",
       "    19                                               #        continue\n",
       "    20                                               #    E += np.sum(deltaZ[idx] * rho * grid_weights / ds)\n",
       "    21                                               \n",
       "    22                                               # 1st order\n",
       "    23         1     208017.0 208017.0      0.6      changed_site, grid_points, grid_densweight = read_grid_first_order()\n",
       "    24         1       1069.0   1069.0      0.0      dV = np.zeros(grid_densweight.shape)\n",
       "    25        21         92.0      4.4      0.0      for idx, Z in enumerate(comb):\n",
       "    26        20        120.0      6.0      0.0          if deltaZ[idx] == 0:\n",
       "    27         8         21.0      2.6      0.0              continue\n",
       "    28        12         79.0      6.6      0.0          mapping = build_reindexing_1_cached(idx, changed_site)\n",
       "    29                                                   \n",
       "    30       252       1393.0      5.5      0.0          for j in range(20): \n",
       "    31       240       2028.0      8.4      0.0              if deltaZ[mapping[j]] == 0:\n",
       "    32        96        323.0      3.4      0.0                  continue\n",
       "    33       144        923.0      6.4      0.0              ds = get_grid_ds(j)\n",
       "    34       144     254984.0   1770.7      0.7              dV += deltaZ[idx] * deltaZ[mapping[j]]* ds\n",
       "    35                                                       #E += np.sum(deltaZ[idx] * deltaZ[mapping[j]] * grid_densweight / ds)/2\n",
       "    36         1       1100.0   1100.0      0.0      f = -np.sum(dV * grid_densweight)/2\n",
       "    37         1        260.0    260.0      0.0      print ('f', f)\n",
       "    38         1          7.0      7.0      0.0      E += f\n",
       "    39                                               \n",
       "    40                                               # 2nd order\n",
       "    41         1          4.0      4.0      0.0      del dV, idx\n",
       "    42         1       1253.0   1253.0      0.0      dE = np.zeros(grid_densweight.shape)\n",
       "    43        21         62.0      3.0      0.0      for idx_i, Z_i in enumerate(comb):\n",
       "    44        20        125.0      6.2      0.0          if deltaZ[idx_i] == 0:\n",
       "    45         8         19.0      2.4      0.0              continue\n",
       "    46       252        961.0      3.8      0.0          for idx_j, Z_j in enumerate(comb):\n",
       "    47       240       1213.0      5.1      0.0              if deltaZ[idx_j] == 0:\n",
       "    48        96        265.0      2.8      0.0                  continue\n",
       "    49                                                       \n",
       "    50                                                       # t_i: target for idx_i after rotation\n",
       "    51                                                       # deriv_pair: part of derivative after pair-mapping\n",
       "    52                                                       # deriv_single: part of derivative after single-mapping\n",
       "    53       144   10612639.0  73698.9     29.3              t_i, t_j, deriv_pair, deriv_single = get_deriv_cached(idx_i, idx_j)\n",
       "    54                                                       \n",
       "    55                                                       # pairwise mapping\n",
       "    56       144        843.0      5.9      0.0              if idx_i != idx_j:\n",
       "    57       132        329.0      2.5      0.0                  try:\n",
       "    58       132   18634285.0 141168.8     51.5                      mapping = build_reindexing_2_cached(idx_i, idx_j, t_i, t_j)\n",
       "    59                                                           except:\n",
       "    60                                                               print (idx_i, idx_j, t_i, t_j)\n",
       "    61      2772      11758.0      4.2      0.0                  for j in range(20): \n",
       "    62      2640      17120.0      6.5      0.0                      if deltaZ[mapping[j]] == 0:\n",
       "    63      1056       3016.0      2.9      0.0                          continue\n",
       "    64      1584       8478.0      5.4      0.0                      ds = get_grid_ds(j)\n",
       "    65      1584    3063961.0   1934.3      8.5                      dE += deltaZ[idx_i] *deltaZ[idx_j] * deltaZ[mapping[j]] * ds * deriv_pair\n",
       "    66                                                       \n",
       "    67                                                       # single mapping\n",
       "    68       144        977.0      6.8      0.0              mapping = build_reindexing_1_cached(idx_j, 0)\n",
       "    69      3024      13493.0      4.5      0.0              for j in range(20): \n",
       "    70      2880      19625.0      6.8      0.1                  if deltaZ[mapping[j]] == 0:\n",
       "    71      1152       3278.0      2.8      0.0                      continue\n",
       "    72      1728       9831.0      5.7      0.0                  ds = get_grid_ds(j)\n",
       "    73      1728    3341876.0   1934.0      9.2                  dE += deltaZ[idx_i] * deltaZ[idx_j] * deltaZ[mapping[j]] * ds * deriv_single\n",
       "    74         1        435.0    435.0      0.0      s = -np.sum(dE)/6\n",
       "    75         1        307.0    307.0      0.0      print ('s', s)\n",
       "    76         1          4.0      4.0      0.0      E += s\n",
       "    77                                                       \n",
       "    78         1          2.0      2.0      0.0      return E"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_predictions(comb):\n",
    "    #rho, dsingle, dneigh1, dneigh2, dneigh3, dneigh4, dneigh5 = read_densities()\n",
    "        \n",
    "    E =0#-758.072029908548 # base energy\n",
    "    deltaZ = np.array(comb) - 6\n",
    "        \n",
    "    zs = np.array([int(_) for _ in comb])\n",
    "    zsref = np.zeros(20) + 6\n",
    "    \n",
    "    E -= get_nucnuc(zsref)\n",
    "    E += get_nucnuc(zs)\n",
    "    print ('nn', E)\n",
    "    \n",
    "    # 0-th order, no rotation necessary, should be hard zero\n",
    "    #ds = np.linalg.norm(grid_points - c.coordinates[0], axis=1)\n",
    "    #es = (rho * grid_weights / ds).sum()\n",
    "    #for idx, Z in enumerate(comb):\n",
    "    #    if deltaZ[idx] == 0:\n",
    "    #        continue\n",
    "    #    E += np.sum(deltaZ[idx] * rho * grid_weights / ds)\n",
    "    \n",
    "    # 1st order\n",
    "    changed_site, grid_points, grid_densweight = read_grid_first_order()\n",
    "    dV = np.zeros(grid_densweight.shape)\n",
    "    for idx, Z in enumerate(comb):\n",
    "        if deltaZ[idx] == 0:\n",
    "            continue\n",
    "        mapping = build_reindexing_1_cached(idx, changed_site)\n",
    "        \n",
    "        for j in range(20): \n",
    "            if deltaZ[mapping[j]] == 0:\n",
    "                continue\n",
    "            ds = get_grid_ds(j)\n",
    "            dV += deltaZ[idx] * deltaZ[mapping[j]]* ds\n",
    "            #E += np.sum(deltaZ[idx] * deltaZ[mapping[j]] * grid_densweight / ds)/2\n",
    "    f = -np.sum(dV * grid_densweight)/2\n",
    "    print ('f', f)\n",
    "    E += f\n",
    "    \n",
    "    # 2nd order\n",
    "    del dV, idx\n",
    "    dE = np.zeros(grid_densweight.shape)\n",
    "    for idx_i, Z_i in enumerate(comb):\n",
    "        if deltaZ[idx_i] == 0:\n",
    "            continue\n",
    "        for idx_j, Z_j in enumerate(comb):\n",
    "            if deltaZ[idx_j] == 0:\n",
    "                continue\n",
    "            \n",
    "            # t_i: target for idx_i after rotation\n",
    "            # deriv_pair: part of derivative after pair-mapping\n",
    "            # deriv_single: part of derivative after single-mapping\n",
    "            t_i, t_j, deriv_pair, deriv_single = get_deriv_cached(idx_i, idx_j)\n",
    "            \n",
    "            # pairwise mapping\n",
    "            if idx_i != idx_j:\n",
    "                try:\n",
    "                    mapping = build_reindexing_2_cached(idx_i, idx_j, t_i, t_j)\n",
    "                except:\n",
    "                    print (idx_i, idx_j, t_i, t_j)\n",
    "                for j in range(20): \n",
    "                    if deltaZ[mapping[j]] == 0:\n",
    "                        continue\n",
    "                    ds = get_grid_ds(j)\n",
    "                    dE += deltaZ[idx_i] *deltaZ[idx_j] * deltaZ[mapping[j]] * ds * deriv_pair\n",
    "            \n",
    "            # single mapping\n",
    "            mapping = build_reindexing_1_cached(idx_j, 0)\n",
    "            for j in range(20): \n",
    "                if deltaZ[mapping[j]] == 0:\n",
    "                    continue\n",
    "                ds = get_grid_ds(j)\n",
    "                dE += deltaZ[idx_i] * deltaZ[idx_j] * deltaZ[mapping[j]] * ds * deriv_single\n",
    "    s = -np.sum(dE)/6\n",
    "    print ('s', s)\n",
    "    E += s\n",
    "            \n",
    "    return E\n",
    "%lprun -f get_predictions print (get_predictions([int(_) for _ in '57766576666555776675']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.908634707589954e-07\n",
      "-1157.6925133820623\n"
     ]
    }
   ],
   "source": [
    "t_i, t_j, deriv_pair, deriv_single = get_deriv(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.77058213579852"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(deriv_single*grid_densweight).sum()+(grid_densweight*deriv_pair).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.37559903, -0.02999852, -0.01814542])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_points[grid_points[:, 0] > 0].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.02408955, -0.33274665, -0.20564775])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.coordinates[c.coordinates[:, 0] > 0].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.93470997786"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.02408955*1.8892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis]",
   "language": "python",
   "name": "conda-env-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
